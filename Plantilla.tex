\documentclass[12pt,letterpaper]{article}
\renewcommand{\rmdefault}{phv} % Cambiar la fuente a Arial
\hbadness=99999 % Evitar mensaje de advertencia

\usepackage[left=4cm,right=2cm,top=3cm,bottom=3cm]{geometry} % Margenes
\usepackage[spanish,es-tabla]{babel} % Cambia el texto "Cuadro" por "Tabla"
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc} % Para aceptar caracteres en español: tilde, ñ, etc.
\usepackage{amsmath}
\usepackage{amssymb,amsfonts,cancel}
\usepackage{array}
\usepackage{enumerate} 
\usepackage{etoolbox}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{graphicx}
\usepackage[pdfstartpage=1,backref=false,pagebackref=false,pdfborder={0 0 0},colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
%\usepackage[none]{hyphenat} %evita la separación de palabras
\usepackage[round,authoryear]{natbib}
\usepackage{longtable}
\usepackage{multicol} % Dividir en columnas
\usepackage{multirow}
\usepackage{ragged2e}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{titlesec}
\usepackage{titletoc} % alinear títulos en tabla de contenido
\usepackage{titling} % Cambiar secciones
\usepackage{colortbl} % agrega colores a columnas
\usepackage{xcolor}
\usepackage{tabularx} % Necesario para el tipo de columna X
\usepackage{enumitem}
\usepackage{pgfgantt}
\usepackage{tikz}


\usepackage[table]{xcolor}
\definecolor{azulUAO}{HTML}{215C98}
\definecolor{azulUAO2}{HTML}{a6c9ec}

\usepackage{rotating}

\fancyhead{}
\fancyfoot[c]{\thepage}

\pagestyle{fancy}

\usepackage{tocloft}
\addto\captionsenglish{\renewcommand{\contentsname}{Contenido}}
\renewcommand{\cfttoctitlefont}{\hfill\normalsize}
\renewcommand{\cftaftertoctitle}{\hfill}
\renewcommand{\cftloftitlefont}{\hfill\normalsize}
\renewcommand{\cftafterloftitle}{\hfill\mbox{}}
\renewcommand{\cftlottitlefont}{\hfill\normalsize}
\renewcommand{\cftafterlottitle}{\hfill\mbox{}}

\renewcommand{\cftfigfont}{Fig. }
\renewcommand{\cfttabfont}{TABLA }
\renewcommand{\spanishtablename}{TABLA}

\usepackage{layout} % Carga el paquete layout
%\usepackage{showframe} % muestra los márgenes y el área del contenido

\titleclass{\subsubsubsection}{straight}[\subsection]
\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % para las subsecciones numeradas

\titleformat{\section}[block]{\bfseries\centering}{\thesection.}{1em}{} % Configuración títulos1
\titleformat{\subsection} % Configuración de título2
  {\normalfont\normalsize\bfseries\MakeUppercase}{\thesubsection}{1em}{}
\titlespacing*{\subsection}{0pt}{0em}{0em}
\titleformat{\subsubsection} % Configuración de título3
  {\normalfont\normalsize\bfseries}{\thesubsubsection}{1em}{}
\titlespacing*{\subsubsection}{0pt}{0em}{0em}
\titleformat{\subsubsubsection} % Configuración de título4
  {\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}{0pt}{0em}{0em}

\makeatletter % Quitar sangria en listas
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {0em}% {3.25ex \@plus1ex \@minus.2ex}
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {0em}% {3.25ex \@plus1ex \@minus.2ex}
  {-1em}%
  {\normalfont\normalsize\bfseries}}  
\def\toclevel@subsection{2}
\def\toclevel@subsubsection{3}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@paragraph{6}
\setlength{\cftsecindent}{0pt}
\setlength{\cftsubsecindent}{0pt}
\setlength{\cftsubsubsecindent}{0pt}
%\setlength{\cftsubsubsubsecindent}{0pt} % Para su custom subsubsubsection
\setlength{\cftfigindent}{0pt} 
\setlength{\cfttabindent}{0pt}

\g@addto@macro\cftsecpagefont{\bfseries}
\g@addto@macro\cftsubsecpagefont{\bfseries\MakeUppercase}
\g@addto@macro\cftparapagefont{\bfseries} 
\g@addto@macro\cftsubparapagefont{\bfseries}
\g@addto@macro\cftfigpagefont{\bfseries} % coloca en negrita los números de página de lof
\g@addto@macro\cfttabpagefont{\bfseries} % coloca en negrita los números de página de lot

\makeatother

\setcounter{secnumdepth}{4} % indica cantidad de niveles de títulos a mostrar
\setcounter{tocdepth}{4}
% Fin Configuración de subtítulos

%\title{Plantilla Latex CRAI-UAO}
%\date{January 23 2019}

\makeatletter % Cambiar : por . y ponerlo en negrita
\newcolumntype{U}[0]{>{$}c<{$}} % Nuevo formato para columnas con fórmula
\renewcommand{\fnum@table}[1]{\textbf{\tablename~\thetable}. \sffamily}
\renewcommand\thetable{\Roman{table}}
\makeatother

\renewcommand{\headrulewidth}{0pt}
\raggedbottom % Quita espacios en blanco    ***Revisar si se necesita

\setlength{\arrayrulewidth}{1pt}
\setlength{\doublerulesep}{0mm}
\setlength{\parindent}{0em} % Quitar sangría de primera línea
\setlength{\parskip}{2em} % Espaciado doble

\begin{document}
%\layout % muestra el layout
\definecolor{lightgray}{rgb}{0.75, 0.75, 0.75} % Define the light gray color


\makeatletter % Cambiar : por . y ponerlo en negrita
\renewcommand{\fnum@figure}[1]{\textbf{\figurename~\thefigure}. \sffamily}
\renewcommand{\figurename}{\textbf{Fig.}} % Cambiar Figura: por Fig. y ponerlo en negrita
\makeatother

\thispagestyle{empty}
\begin{center}
	\includegraphics[scale=1]{Figuras/horizontal-color}
\end{center}
\vspace{2.5cm}

\textbf{DATOS GENERALES DEL ESTUDIANTE}
\vspace{-0.5cm}

\begin{tabularx}{\textwidth}{|>{\columncolor{lightgray}}l|X|}\hline
\textbf{Nombre Estudiante} & Jorge Andrés Jaramillo Neme\\\hline 
\textbf{Programa Académico} & Maestría en IA y Ciencia de Datos \\\hline
\textbf{Cédula} & 1.144.084.317 \\\hline
\textbf{Código Estudiantil} & 22505049 \\\hline
\textbf{Correo} & Jorge\_and.jaramillo@uao.edu.co \\\hline
\end{tabularx}

% Si hay un segundo autor descomente las siguientes líneas
%\begin{tabularx}{\textwidth}{|>{\columncolor{lightgray}}l|X|}\hline
%\textbf{Nombre Estudiante} & \textcolor{red}{Escriba acá su nomnbre}\\\hline
%\textbf{Programa Académico} & \\\hline
%\textbf{Cédula} & \\\hline
%\textbf{Código Estudiantil} & \\\hline
%\textbf{Correo} & \\\hline
%\end{tabularx}

\textbf{DATOS GENERALES DEL DIRECTOR}
\vspace{-0.5cm}

\begin{tabularx}{\textwidth}{|>{\columncolor{lightgray}}l|X|}\hline
\textbf{Nombre Director} & Javier Ferney Castillo García \\\hline
\textbf{Correo} &  jfcastillo@uao.edu.co\\\hline
%\textbf{Nombre Codirector} &  \\\hline
%\textbf{Correo} &  \\\hline
\end{tabularx}

\textbf{DATOS DEL ANTEPROYECTO}
%\vspace{-0.5cm}

\begin{longtable}{|p{\dimexpr\textwidth-2\tabcolsep-2\arrayrulewidth}|}
\hline
\rowcolor{lightgray}\centering\arraybackslash\textbf{TÍTULO DEL PROYECTO} \\ \hline
 \textbf{Desarrollo de un sistema agentico basado en grafos de conocimiento y modelos de lenguaje pequeños para la verificación estructural automatizada de propuestas de investigación}\\\hline

\rowcolor{lightgray}\centering\arraybackslash\textbf{PALABRAS CLAVES/KEY WORDS} \\\hline
Sistemas Agenticos, modelos pequeños de lenguaje, ingeniería de contexto, grafos de conocimiento / Agentic AI, Small Language Models, Context Engineering, Knowledge Graphs.
 \\\hline
\rowcolor{lightgray}\centering\arraybackslash\textbf{RESUMEN} \\\hline
Se presenta un anteproyecto de maestría orientado a abordar la problemática de la coherencia y consistencia estructural en documentos de investigación académica (anteproyectos, proyectos y artículos científicos). A pesar de los avances en herramientas digitales de escritura y en Modelos de Lenguaje de Gran Escala (LLM, Large Language Models), persiste la dificultad de garantizar una alineación rigurosa entre el problema de investigación, los objetivos, la metodología y el sustento teórico. La naturaleza estadística de los LLM y fenómenos como la “amnesia contextual” limitan su capacidad para preservar relaciones causales y dependencias metodológicas en textos extensos, lo que genera vacíos en el aseguramiento de la calidad estructural de los documentos científicos. Frente a este escenario, el objetivo general de este trabajo es diseñar e implementar un prototipo de sistema agéntico copiloto, basado en ingeniería de contexto, que integre grafos de conocimiento (Knowledge Graphs, KG) y modelos de lenguaje pequeños (Small Language Models, SLM), para asistir en la evaluación de la coherencia y consistencia de proyectos de investigación. Metodológicamente, la propuesta se enmarca en un enfoque aplicado–experimental, con predominio cuantitativo y un componente cualitativo complementario. El estudio se desarrolla en fases que incluyen: análisis conceptual y documental de estructuras metodológicas y criterios de coherencia; modelado semántico mediante una ontología y su implementación en un grafo de conocimiento; diseño de la arquitectura agéntica y de sus módulos cognitivos (lectura, verificación, razonamiento, navegación y gestión de memoria contextual); implementación del prototipo integrando KG, SLM y flujos de razonamiento multi-agente; y una etapa de evaluación que combina métricas automáticas de desempeño con la valoración experta en un entorno controlado. Se espera obtener un copiloto cognitivo capaz de representar explícitamente las relaciones entre problema, objetivos, metodología y literatura, detectar desalineaciones o inconsistencias y ofrecer retroalimentación accionable al investigador. Como aporte principal, el proyecto busca avanzar en la integración de sistemas agénticos, grafos de conocimiento e ingeniería de contexto para el aseguramiento estructural de documentos científicos, sentando bases metodológicas y tecnológicas para futuros ecosistemas de apoyo inteligente a la investigación.
\\\hline
\end{longtable}
\setcounter{table}{0}

\begin{titlepage}
   \begin{center}
		\textbf{{\MakeUppercase {Desarrollo de un sistema agentico basado en grafos de conocimiento y modelos de lenguaje pequeños para la verificación estructural automatizada de propuestas de investigación}}\\
		\vspace{4cm}
		\includegraphics[scale=1.2]{Figuras/horizontal-color}\\
		\vspace{4cm}
		{\MakeUppercase {{JORGE ANDRÉS JARAMILLO NEME}} \\
		{22505049}}\\
		\vfill
		{UNIVERSIDAD AUTÓNOMA DE OCCIDENTE} \\
		{\MakeUppercase {FACULTAD DE INGENIERÍA Y CIENCIAS BÁSICAS}} \\ 
		{\MakeUppercase {PROGRAMA DE MAESTRÍA EN INTELIGENCIA ARTIFICIAL Y CIENCIA DE DATOS}} \\
		{SANTIAGO DE CALI} \\
		{2025}} \\ 
	\end{center} 
\end{titlepage}

\newpage
\begin{titlepage}
   \begin{center}

        \textbf{\MakeUppercase{Desarrollo de un sistema agentico basado en grafos de conocimiento y modelos de lenguaje pequeños para la verificación estructural automatizada de propuestas de investigación}}\\
        
        \vspace{2cm}
        \includegraphics[scale=1.2]{Figuras/horizontal-color}\\
        \vspace{2cm}

        \textbf{\MakeUppercase{JORGE ANDRÉS JARAMILLO NEME}}\\
        
        \vspace{2cm}
        \textbf{Anteproyecto de grado para optar al título de}\\
        \textbf{Magíster en Inteligencia Artificial y Ciencia de Datos}\\

        \vspace{1cm}
        \textbf{Director}\\
        \textbf{\MakeUppercase{Javier Ferney Castillo García}}\\
        \textbf{Ph.D. en Ingeniería Eléctrica y Electrónica, 2015, Universidad del Valle, Colombia}\\
        \textbf{Magíster en Ingeniería Eléctrica, 2014, Universidade Federal do Espírito Santo, Brasil}\\
        \textbf{Magíster en Automática, 2009, Universidad del Valle, Colombia}\\
        \textbf{Ingeniero Electrónico, 2004, Universidad del Valle, Colombia}\\
  
        \vfill
        \textbf{UNIVERSIDAD AUTÓNOMA DE OCCIDENTE}\\
        \textbf{\MakeUppercase{FACULTAD DE INGENIERÍA Y CIENCIAS BÁSICAS}}\\
        \textbf{\MakeUppercase{PROGRAMA DE MAESTRÍA EN INTELIGENCIA ARTIFICIAL Y CIENCIA DE DATOS}}\\
        \textbf{SANTIAGO DE CALI}\\
        \textbf{2025}

    \end{center}
\end{titlepage}



\setcounter{page}{3} % Inicia la numeración de páginas

\makeatletter
\renewcommand{\cftdotsep}{10000} % Quitar puntos en la tabla de contenido
\makeatother

\setlength{\cftfigindent}{0pt} % quita la sangria en la lista de figuras
\setlength{\cfttabindent}{0pt} % quita la sangria en la lista de tablas

\newpage
\noindent\renewcommand{\contentsname}{\textbf{CONTENIDO}} % Quita el espacio superior y cambia el nombre
\vspace{-1cm}
\addtocontents{toc}{\hfill \textbf{pág.} \par}
\textbf{\tableofcontents}

\newpage
\section*{INTRODUCCIÓN}
\vspace{-0.5cm}
\addcontentsline{toc}{section}{INTRODUCCIÓN}
La historia del desarrollo humano y científico puede interpretarse, fundamentalmente, como una continua búsqueda de métodos para la resolución de problemas. Desde los albores de la ciencia moderna, la necesidad de transformar una idea abstracta en una solución tangible ha obligado a la humanidad a estructurar su pensamiento. Lo que antiguamente se limitaba a la intuición, evolucionó hacia la formalización del método científico y, en la era contemporánea, se ha sistematizado bajo lo que hoy conocemos como la formulación de proyectos de investigación. Este proceso constituye la arquitectura intelectual necesaria para abordar la complejidad, exigiendo una alineación precisa entre la identificación de una necesidad (el problema) y la estrategia para resolverla \citep{Miles2019}.

Históricamente, la producción de estos documentos ha sido una actividad central en la academia. Sin embargo, con la llegada de la revolución digital y las plataformas colaborativas, aunque se facilitó la escritura, se contribuyó poco a resolver el desafío de fondo: garantizar la solidez estructural del planteamiento. La alineación lógica entre un problema, sus objetivos y su metodología \citep{Covvey2023} siguió siendo una tarea manual, sujeta a errores humanos y fatiga cognitiva.

En la última década, el panorama cambió con la irrupción de la Inteligencia Artificial Generativa y los Modelos de Lenguaje de Gran Escala (LLMs). Herramientas como GPT o BERT demostraron una capacidad sin precedentes para generar texto fluido. No obstante, al integrarse en la investigación, surgió una paradoja: estos modelos operan como excelentes redactores, pero como deficientes metodólogos. Carecen de una comprensión profunda de las dependencias causales que exige un proyecto, sufriendo a menudo de "amnesia contextual" \citep{Huang2025} y generando propuestas que, aunque elocuentes, presentan fisuras lógicas estructurales.

Es en esta coyuntura donde la presente investigación encuentra su máxima pertinencia. En el actual escenario de competitividad académica global, la exigencia ha escalado drásticamente. Ya no basta con redactar documentos extensos; para lograr la aceptación en revistas de alto impacto (Q1/Q2) o el éxito en convocatorias de financiación cada vez más reñidas, se requiere que los papers y propuestas estén rigurosamente alineados. Los evaluadores y organismos financiadores penalizan severamente las inconsistencias metodológicas, donde los objetivos no tributan al problema o la metodología no responde a la pregunta de investigación. La capacidad de producir documentos no solo "bien escritos", sino estructuralmente blindados, se ha convertido en el factor diferenciador para la viabilidad de la investigación moderna.
Para responder a este desafío, surgen enfoques avanzados como la Ingeniería de Contexto, que busca diseñar arquitecturas que controlen la lógica de la información \citep{Zhuang2025}. 


La evolución hacia Sistemas Agénticos y el uso de Grafos de Conocimiento ofrece una vía para representar explícitamente las reglas de un proyecto. La integración de estas tecnologías, apoyada por la eficiencia de Modelos de Lenguaje Pequeños (SLMs), abre la puerta a una nueva generación de asistentes capaces de validar la estructura profunda de una propuesta.

Bajo este marco, el propósito central de este trabajo de grado es desarrollar un prototipo de sistema agéntico copiloto que incorpore una arquitectura de ingeniería de contexto basada en grafos de conocimiento \citep{Ibrahim2024} y SLMs. La finalidad es asistir en la evaluación automatizada de la coherencia y consistencia de proyectos de investigación. Se busca crear una herramienta que actúe como un "garante metodológico", elevando el estándar de calidad de la producción científica y potenciando las posibilidades de éxito de los investigadores ante las exigencias de publicación y financiación actuales.

Para alcanzar este propósito, se ha adoptado una metodología de tipo investigación aplicada con un componente de desarrollo tecnológico experimental. El estudio se estructura en cuatro fases secuenciales: el análisis de los criterios de coherencia, el diseño de un modelo ontológico (grafo de conocimiento), la implementación técnica de la arquitectura agéntica con SLMs, y finalmente, la evaluación del desempeño del prototipo mediante pruebas controladas.

La propuesta de valor de este proyecto no sólo se centra en el uso aplicado de sistemas agenticos, sino en una estrategia de Ingeniería de contexto más elaborada y personalizada, que permita una coordinación, planeación, y visibilidad por parte del sistema enriquecida, que produzca resultados más acertados, mitigando las alucinaciones y garantizando la rigurosidad crítica que exige la formulación de proyectos de investigación en la frontera del conocimiento actual.

\newpage
\section{PLANTEAMIENTO DEL PROBLEMA}
\vspace{-0.5cm}
En los entornos actuales de investigación, la producción de documentos de carácter metodológico como propuestas de investigación y publicaciones científicas, exige integrar grandes volúmenes de información proveniente de fuentes heterogéneas. Estos documentos deben mantener consistencia entre objetivos, metodología y resultados, así como coherencia narrativa y conceptual a lo largo de múltiples secciones y demás referencias de trabajos relacionados. Sin embargo, la elaboración y revisión de este tipo de contenidos continúa siendo un proceso altamente demandante en tiempo y esfuerzo cognitivo, pues depende de la capacidad humana para organizar, relacionar y justificar información dispersa bajo criterios normativos y metodológicos específicos \citep{Miles2019}.

Las herramientas actuales de inteligencia artificial generativa, aunque han transformado las tareas de redacción y corrección, aún operan principalmente en el plano lingüístico. Su funcionamiento, basado en la predicción estadística de palabras, no les permite comprender
ni mantener las relaciones causales o jerárquicas que definen la validez estructural de un proyecto \citep{Zhuang2025}.
Este fenómeno se conoce como amnesia contextual o estructural a largo plazo, y es crítico cuando el documento excede la ventana de contexto de los modelos, o cuando una modificación sutil en una sección genera una inconsistencia lógica en otra lejana. Las soluciones basadas únicamente en RAG (Generación Aumentada por Recuperación) abordan la factualidad, pero no la consistencia lógica interna del documento \citep{Singh2025}.

La disciplina de la Ingeniería de Contexto emerge precisamente para resolver esta brecha, enfocándose en el diseño de arquitecturas que superan la amnesia contextual al alimentar los modelos con información estructurada y precisa en el momento. En este marco, la representación del conocimiento mediante Grafos de Conocimiento \citep{Mohamed2025} (KG) ofrece una solución prometedora al permitir modelar las dependencias semánticas como una base de verdad dinámica (Ground Truth), facilitando la trazabilidad estructural. No obstante, la integración de esta arquitectura para la co-construcción y validación activa de documentos metodológicos aún representa un desafío de investigación.

Paralelamente, la investigación en razonamiento automatizado y extracción de relaciones a nivel documental ha mostrado avances significativos desde hace varios años. Estudios \citep{Nan2020} han demostrado que los modelos pueden inferir relaciones entre entidades distribuidas en múltiples oraciones, abriendo posibilidades para representar conexiones semánticas complejas. Otros trabajos \citep{Li2022}, han incorporado redes de grafos heterogéneos y mecanismos de atención, permitiendo modelar interdependencias entre conceptos y entidades dentro de un texto. Sin embargo, estas aproximaciones se han limitado a tareas de análisis de información, sin ser extrapoladas a procesos de construcción, revisión o co-construcción de documentos técnicos o científicos, donde la coherencia y la trazabilidad son críticas.

Por otra parte, la evolución de los Sistemas Agénticos permite la orquestación de flujos de trabajo documentales complejos. Investigaciones como Verify-Agent \citep{Chu2024} o MMA-RAG \citep{Krayem2025} muestran el potencial de los agentes especializados para tareas de inspección y validación. Sin embargo, la implementación de estos sistemas se enfrenta a desafíos de eficiencia computacional y latencia en tareas de extracción. Para resolver esto, el uso de Modelos de Lenguaje Pequeños (SLMs), optimizados para la traducción de texto natural a formatos estructurados (Text-to-Graph), se presenta como una vía técnica para lograr la extracción semántica eficiente y el bajo costo operacional dentro del sistema agéntico.

La convergencia de estos avances revela un vacío metodológico y tecnológico: la inexistencia de una arquitectura de Ingeniería de Contexto que utilice el KG como motor de estado y los SLMs como extractores eficientes para habilitar la Verificación Estructural Automatizada de documentos de investigación. La falta de este sistema de validación lógica impide a los profesionales y académicos aprovechar plenamente el poder generativo de la IA sin sacrificar la coherencia y el rigor.

En paralelo, la evolución de la Inteligencia Artificial agéntica y los sistemas multi-agente plantea nuevas posibilidades para el procesamiento de conocimiento complejo. Investigaciones como Verify-Agent \citep{Chu2024} muestran el potencial de varios agentes especializados que colaboran en tareas de inspección y validación de plantillas, mientras MMA-RAG \citep{Krayem2025} introduce agentes capaces de combinar datos estructurados y no estructurados para gestionar información regulada. A su vez, las propuestas arquitectónicas como las de \citep{Khamis2025} destacan la capacidad de estos sistemas para planificar, razonar y coordinar acciones de manera autónoma. Pese a ello, los desarrollos actuales se enfocan en dominios cerrados o experimentales, sin abordar la integración de agentes cognitivos y representaciones semánticas para la comprensión y co-estructuración de documentos de carácter metodológico mencionados.

Esta búsqueda revela un vacío metodológico y tecnológico: la inexistencia de un marco que combine agentes de IA capaces de razonar con modelos explícitos de conocimiento (como grafos u ontologías) aplicados a la construcción, análisis y validación de documentos estructurados. La falta de herramientas de este tipo conlleva que las organizaciones y profesionales sigan dependiendo de procesos manuales, fragmentados y susceptibles de incoherencias o pérdidas de trazabilidad. 

Explorar la convergencia entre IA agéntica y grafos de conocimiento representa, dentro de una estrategia avanzada de Ingeniería de Contexto, representa una oportunidad para crear un copiloto cognitivo que no solo redacte, sino que comprenda y razone sobre la estructura y el contenido de los documentos, detectando incoherencias, evaluando consistencia y manteniendo alineación entre las partes. Este tipo de sistema podría transformar la manera en que se desarrollan documentos técnicos, científicos o institucionales, fortaleciendo la eficiencia cognitiva y la calidad estructural de los resultados producidos.

\subsection{Pregunta de Investigación}
\vspace{-0.5cm}
¿Cómo una estrategia de ingeniería de contexto basada en grafos de conocimiento, apoyada en modelos de lenguaje pequeños (SLMs), mejora la capacidad de un sistema agéntico para reducir las inconsistencias lógicas y fortalecer la coherencia y consistencia de propuestas de investigación?
\newpage
\section{OBJETIVOS}
\vspace{-0.5cm}

\subsection{Objetivo General}
\vspace{-0.5cm}
Desarrollar un prototipo de sistema agéntico copiloto que incorpore una arquitectura de ingeniería de contexto basada en grafos de conocimiento y Small Language Models (SLMs), para asistir la evaluación automatizada de la coherencia y consistencia de proyectos de investigación.

\subsection{Objetivos Específicos}
%\vspace{-0.5cm}
\begin{enumerate}[label=\textbf{\thesubsection.\arabic*}, leftmargin=*, labelsep=1em, itemsep=0.5em, topsep=0.5em]
    \item Analizar las estructuras y componentes de los proyectos de investigación, identificando los criterios de coherencia y consistencia relevantes para su evaluación automatizada.
    
    \item Diseñar un modelo semántico-ontológico, implementado como grafo de conocimiento, que represente las relaciones y dependencias lógicas entre los componentes estructurales de los proyectos de investigación.
    
    \item Implementar la arquitectura de ingeniería de contexto del sistema agentico copiloto, integrando el grafo de conocimiento y los Small Language Models (SLMs) para apoyar el procesamiento y estructuración del contenido textual.
    
    \item Validar el desempeño sistémico y la efectividad del prototipo agéntico para diagnosticar y fortalecer la coherencia y consistencia metodológica de proyectos de investigación, mediante la aplicación de técnicas especializadas de evaluación de LLM y sistemas agénticos en un entorno controlado.
\end{enumerate}


\newpage
\section{JUSTIFICACIÓN Y ALCANCE}
\vspace{-0.5cm}
La creación de documentos extensos es una actividad central en contextos académicos y profesionales, y sus deficiencias suelen derivarse más de la fragmentación del conocimiento que de la falta de información disponible. En los proyectos de investigación, la coherencia entre problema, objetivos, metodología y marco teórico depende de mantener una representación estable de las decisiones conceptuales, algo que los sistemas actuales de asistencia basados en modelos de lenguaje no logran con solidez, pues operan principalmente sobre texto plano y carecen de mecanismos para preservar conocimiento estructurado. Esto limita su capacidad para validar coherencia interna, verificar consistencia lógica y contextualizar el contenido frente a metas, restricciones, y referencias definidas por el investigador.

En este contexto, una estrategia de ingeniería de contexto basada en grafos de conocimiento y Small Language Models (SLMs, modelos de lenguaje pequeños) ofrece una oportunidad para dotar a los sistemas agénticos de un entendimiento más aterrizado (grounded), apoyado en estructuras semánticas y referencias explícitas. Integrar un enfoque agéntico con una base de conocimiento estructurada permite distribuir tareas cognitivas como la verificación de coherencia entre secciones, la evaluación de consistencia terminológica y conceptual, y la comprobación de que las afirmaciones del documento se encuentran respaldadas por la literatura relevante seleccionada por el usuario. El grafo de conocimiento actúa como memoria contextual y soporte de razonamiento, mientras agentes especializados coordinan lectura, extracción, contraste y verificación, en línea con arquitecturas que combinan agentes y razonamiento simbólico para tareas de planificación o validación en dominios específicos \citep{Bonifazi2025}.

El presente trabajo se enfoca en el desarrollo de una estrategia de ingeniería de contexto orientada a la evaluación y verificación contextual de proyectos de investigación, con dos capacidades principales del sistema agéntico copiloto: (i) evaluar la coherencia y consistencia interna entre los componentes estructurales del proyecto y (ii) contrastar dichos componentes con un conjunto de artículos y referencias aportadas por el usuario, valorando su relevancia y alineación temática. El alcance se limita a un escenario controlado de proyectos de investigación académica, con un conjunto acotado de componentes y referencias, sin pretender cubrir todo el ciclo de vida de la investigación ni sustituir el criterio del investigador. En cambio, se busca ofrecer un copiloto especializado en detectar inconsistencias lógicas, desalineaciones conceptuales y debilidades de soporte bibliográfico.

 El desarrollo de un prototipo bajo estos lineamientos permitirá avanzar hacia sistemas capaces de interpretar, estructurar y revisar conocimiento de forma más cercana al razonamiento humano, reduciendo la carga de revisión manual y mejorando la trazabilidad de las decisiones conceptuales, a la vez que genera evidencia empírica sobre la efectividad de la estrategia de ingeniería de contexto y sienta bases para escalar, en el mediano plazo, hacia un ecosistema más amplio de apoyo a la investigación.
\newpage
\section{ANTECEDENTES Y ESTADO DEL ARTE}
\vspace{-0.5cm}

El desarrollo de los modelos basados en la arquitectura Transformer \citep{Vaswani2017} marcó un cambio estructural en la forma en que la inteligencia artificial aborda la comprensión y generación del lenguaje natural. A diferencia de las redes recurrentes y convolucionales, los Transformers utilizan mecanismos de atención que permiten procesar relaciones entre todas las partes de una secuencia en paralelo, lo cual amplió drásticamente la capacidad para capturar dependencias a largo plazo y contextos extensos. Esta innovación dio origen a los Large Language Models (LLMs), como GPT, BERT o T5, que demostraron un comportamiento emergente \citep{Long2022} de razonamiento, planificación y adaptación contextual que antes no estaba presente en modelos puramente estadísticos.

Los LLMs introdujeron la posibilidad de modelar tareas complejas de manera unificada, sin requerir entrenamiento específico para cada una, mediante el uso de prompting y aprendizaje en contexto. Estos avances sentaron las bases para la creación de agentes inteligentes basados en lenguaje, capaces de interpretar instrucciones y ejecutar acciones, trascendiendo la generación textual hacia la resolución de problemas autónomos, lo cual ha ido mejorando en su asertividad para resolver problemas complejos con modelos razonadores. En este punto surge la noción de AI Agent, entendida como una entidad que utiliza un modelo de lenguaje como núcleo cognitivo para interactuar con su entorno, tomar decisiones y cumplir objetivos definidos a partir de la comprensión de instrucciones textuales \citep{Acharya2025}

El concepto de agente basado en LLM evolucionó hacia arquitecturas más complejas denominadas Agentic AI Systems, las cuales integran múltiples agentes especializados que colaboran para alcanzar metas compartidas. Estos sistemas combinan módulos de razonamiento, memoria y planificación, y se apoyan en mecanismos de comunicación interna para coordinar decisiones. El enfoque agentic trasciende la idea de un único modelo que responde, incorporando la capacidad de reflexión, división del trabajo y evaluación mutua entre agentes \citep{Khamis2025}

Mientras los agentes tradicionales operan bajo entornos cerrados con objetivos definidos, los sistemas agénticos incorporan componentes de autonomía adaptativa y aprendizaje continuo. De acuerdo con la revisión conceptual de \citep{Khamis2025}, un sistema agéntico puede incluir módulos de memoria semántica, episódica y procedimental, mecanismos de handoff para transferencia de contexto, y cueing para activación contextual de agentes, características que les otorgan la capacidad de planificar, razonar y autoevaluarse durante la ejecución de tareas.

El estudio de la agenticidad en inteligencia artificial también ha motivado el desarrollo de marcos de referencia para la evaluación de estos sistemas, considerando métricas que van más allá de la exactitud de salida. Las recientes encuestas en el campo \citep{Asaf2025} proponen clasificaciones que incluyen la evaluación de razonamiento multietapa, uso de herramientas, reflexión y persistencia de memoria, consolidando así una base conceptual que describe la transición de modelos de lenguaje a sistemas con comportamiento autónomo coordinado.


La arquitectura de Retrieval-Augmented Generation \citep{Lewis2021} (RAG) surgió como respuesta al problema de las alucinaciones \citep{Xi2023} y la falta de actualización de los LLMs. Este modelo combina un recuperador externo con un generador interno, de modo que las respuestas no dependen exclusivamente del conocimiento estático aprendido durante el entrenamiento. El componente de recuperación selecciona fragmentos relevantes de un corpus o base de conocimiento, mientras el generador produce la salida final integrando la información obtenida \citep{Singh2025}.

En sus primeras implementaciones, RAG utilizó recuperadores clásicos como BM25, basados en coincidencias de términos. Más adelante, los métodos de recuperación densa permitieron representar tanto las consultas como los documentos en un espacio vectorial común, mejorando la pertinencia semántica de los resultados. Estos avances dieron paso a modelos integrados, en los que la recuperación y la generación se entrenan conjuntamente, reduciendo inconsistencias y aumentando la coherencia entre las fuentes consultadas y la respuesta final \citep{Singh2025}

No obstante, RAG también enfrenta limitaciones. Entre las más relevantes se encuentran la fragmentación del contexto (al integrar fragmentos dispersos sin una estructura explícita) y la dificultad para manejar consultas complejas que requieren razonamiento encadenado o comprensión estructural. Además, el sistema depende fuertemente de la calidad y cobertura de las bases de conocimiento, lo que puede introducir sesgos o información desactualizada \citep{Singh2025}

Para abordar estos problemas, se propusieron extensiones que incorporan reranqueadores (Rerankers) y mecanismos de reflexión. Los reranqueadores priorizan los fragmentos más relevantes tras la recuperación inicial, utilizando modelos especializados o el propio LLM como evaluador. Por su parte, los módulos reflexivos verifican la consistencia del contexto antes de la generación definitiva, evaluando la pertinencia de las fuentes recuperadas \citep{Li2025}
Una evolución significativa de este paradigma es GraphRAG, que sustituye la recuperación basada en texto plano por una recuperación estructurada sobre grafos de conocimiento. En este enfoque, la información se representa mediante entidades, relaciones y propiedades interconectadas, lo que permite consultas semánticas y razonamiento multihop. Según la documentación técnica \citep{Edge2025}, el proceso se compone de tres fases: extracción de entidades y relaciones, indexación del grafo en una base semántica, y recuperación contextual combinada con el generador.

GraphRAG mejora la interpretabilidad y la trazabilidad de las respuestas, ya que cada fragmento generado puede vincularse a las entidades de origen dentro del grafo. Asimismo, resuelve parcialmente la fragmentación del contexto, permitiendo inferencias sobre relaciones indirectas y dependencias jerárquicas. En ámbitos donde la coherencia conceptual es crítica, como en documentos metodológicos, esta integración ofrece ventajas sustanciales para el análisis de consistencia interna y verificación contextual \citep{Colombo2024}

En etapas más recientes, el paradigma evoluciona hacia Agentic RAG, donde distintos agentes desempeñan roles específicos: algunos encargados de recuperar información, otros de verificar la coherencia y otros de sintetizar los resultados finales. Esta orquestación permite incorporar mecanismos de memoria compartida, reflexión distribuida y revisión cooperativa antes de la respuesta. De esta forma, la generación aumentada deja de ser un proceso lineal y se convierte en una interacción iterativa entre agentes especializados \citep{Acharya2025}

El razonamiento multihop o multiescalón es una capacidad esencial para la comprensión compleja y la verificación contextual. Este tipo de razonamiento requiere que un sistema combine información proveniente de múltiples fuentes o pasos intermedios para responder correctamente una consulta. A diferencia del razonamiento directo, que se basa en una única evidencia, el multihop permite inferir relaciones indirectas a través de trayectorias lógicas o semánticas SMORE \citep{Ren2022}.

Los modelos diseñados para razonamiento multihop enfrentan desafíos de escalabilidad, especialmente en grandes grafos de conocimiento o colecciones textuales extensas. El enfoque propuesto por SMORE optimiza la búsqueda bidireccional de trayectorias, utilizando paralelización y estrategias de muestreo que reducen el costo computacional sin sacrificar precisión. Este tipo de arquitectura demuestra que la inferencia encadenada puede mantenerse eficiente incluso en contextos con millones de entidades interconectadas \citep{Ren2022}.

En el ámbito documental, la utilidad del razonamiento multihop radica en la capacidad de vincular distintas secciones de un texto o distintas versiones de un mismo concepto. Por ejemplo, un sistema que analiza un proyecto de investigación puede determinar si los objetivos derivan adecuadamente de la pregunta planteada, o si la metodología corresponde con las hipótesis formuladas. Este tipo de inferencia, que requiere combinar pasos intermedios, resulta clave para medir la coherencia estructural de un documento.

Los grafos de conocimiento constituyen una de las estructuras más relevantes para representar y organizar información compleja. Su formato de tripletas (sujeto, predicado, objeto) permite describir hechos, entidades y relaciones de forma explícita. En la actualidad, los grafos se utilizan no solo como bases de datos semánticas, sino como componentes de razonamiento dentro de sistemas híbridos simbólico-subsimbólicos \citep{Sardina2024}.

Los estudios recientes sobre su estructura y desempeño muestran que factores como el grado de los nodos, la frecuencia de las relaciones y la co-frecuencia de entidades influyen en la calidad de las incrustaciones y en el rendimiento de los modelos de predicción. Un análisis detallado de estos aspectos \citep{Sardina2024}, señala que las distribuciones de grado sesgadas tienden a favorecer la representación de nodos centrales, lo que genera sesgos en tareas de razonamiento o recomendación.

En el ámbito académico y científico, los grafos de conocimiento especializados han ganado importancia como herramientas para integrar literatura, conceptos y relaciones temáticas. Un ejemplo representativo es \citep{Dess2025} que compila más de veinticinco millones de entidades del dominio de la informática, permitiendo consultas semánticas y exploración multihop. Este tipo de infraestructuras evidencia el potencial de los KGs para servir como memoria estructurada en sistemas de análisis o generación asistida.
El vínculo entre los grafos de conocimiento y los sistemas agénticos se vuelve especialmente relevante cuando los primeros se utilizan como fuente de memoria a largo plazo. En ese contexto, los agentes no solo recuperan información, sino que razonan sobre la estructura del grafo, actualizan nodos y relaciones, y verifican consistencia. Así, los KGs dejan de ser bases pasivas de datos para convertirse en componentes activos de la cognición artificial \citep{Colombo2024}

La aplicación de arquitecturas de IA a la creación y manipulación de documentos ha avanzado significativamente con la aparición de sistemas copiloto. Estos entornos combinan modelos de lenguaje, planificación y ejecución de código para automatizar tareas de lectura, edición y verificación. Uno de los desarrollos más destacados es Docpilot \citep{Mathur2024}, presentado por Adobe Research, que demuestra cómo un modelo de lenguaje puede planificar secuencias de acciones, verificar resultados intermedios y autocorregirse con base en errores detectados.

En Docpilot \citep{Mathur2024}, el sistema se compone de cuatro fases: planificación de tareas, verificación y autocorrección, interacción con el usuario y ejecución mediante generación de código. Esta estructura encarna de manera temprana el principio de agencia dentro del procesamiento documental, donde el modelo no solo genera texto, sino que coordina herramientas y ejecuta acciones con retroalimentación automática.

Estos avances muestran la transición de modelos pasivos a sistemas interactivos orientados a objetivos. En entornos académicos, este tipo de herramientas puede evolucionar hacia copilotos cognitivos capaces de analizar la estructura de un proyecto de investigación, verificar la coherencia entre secciones y sugerir mejoras semánticas o metodológicas. La integración con grafos de conocimiento y con arquitecturas agénticas abre la posibilidad de desarrollar sistemas de asistencia que razonen sobre el documento, comprendan su contexto y mantengan coherencia entre versiones y revisiones.


\newpage
\section{MARCO TEÓRICO}
\vspace{-0.5cm}
La presente investigación se enmarca en el estudio de la integración entre los sistemas agénticos basados en inteligencia artificial, los grafos de conocimiento y las técnicas de razonamiento contextual. Su propósito es explorar cómo estas tecnologías pueden combinarse para asistir en la creación y verificación estructural de documentos de carácter metodológico, como los proyectos de investigación.

El trabajo se apoya en tres ejes conceptuales principales:

El primero corresponde a los sistemas agénticos, entendidos como arquitecturas compuestas por agentes inteligentes capaces de razonar, planificar y cooperar para cumplir tareas complejas. El segundo eje se relaciona con los grafos de conocimiento, que permiten representar de manera estructurada las relaciones entre conceptos, secciones y evidencias dentro de un dominio determinado. El tercer eje aborda los enfoques de razonamiento contextual y recuperación aumentada (RAG y GraphRAG), que combinan la generación de lenguaje con la recuperación de información relevante desde fuentes estructuradas.

En este marco, resulta necesario describir y analizar los fundamentos de cada una de estas áreas: los principios de funcionamiento de los sistemas agénticos, los modelos ontológicos y de representación semántica propios de los grafos de conocimiento, las bases de los métodos de generación aumentada por recuperación y las técnicas de razonamiento multihop empleadas para la verificación contextual de información.

5.1	Sistemas Agenticos versus Agentes de AI

Los sistemas agénticos basados en inteligencia artificial, conocidos como Agentic AI Systems, representan una evolución reciente en el desarrollo de arquitecturas cognitivas que combinan modelos de lenguaje avanzados con componentes de razonamiento, memoria y control autónomo. 

A diferencia de los AI Agents tradicionales, que se definen como entidades individuales diseñadas para ejecutar tareas específicas bajo reglas preestablecidas, los sistemas agénticos constituyen un conjunto coordinado de agentes especializados que interactúan entre sí dentro de una arquitectura estructurada y orientada a objetivos.

Un sistema agéntico se concibe como una entidad compuesta por múltiples módulos funcionales que colaboran de forma dinámica para resolver problemas complejos. Según \cite{Khamis2025}, la estructura básica de estos sistemas integra tres niveles principales: el nivel de percepción y comprensión del entorno, el nivel de razonamiento y planificación, y el nivel de acción o ejecución. Cada uno de estos niveles está asistido por memorias que almacenan información semántica, contextual y procedimental, permitiendo que el sistema aprenda de la experiencia y mantenga coherencia a lo largo de distintas interacciones.

\begin{figure}[H]
\centering
  \includegraphics[scale=1]{Figuras/foto1_anteproyecto.png}
  \caption{Tomado de \citep{Sapkota2025}}
\vspace{-0.5cm}
\end{figure}

Los componentes estructurales más representativos de un sistema agéntico son los siguientes:

Modelo base o núcleo cognitivo: normalmente un modelo de lenguaje o razonamiento (LLM o LRM) que interpreta instrucciones, genera hipótesis y produce salidas lingüísticas o simbólicas.

Módulos cognitivos especializados: agentes encargados de tareas concretas como lectura, análisis, evaluación o verificación. Estos módulos pueden operar en paralelo y coordinarse mediante mecanismos de intercambio de contexto.

Sistema de memoria: compuesto por memorias semánticas, episódicas y procedimentales. La memoria semántica contiene conocimiento estable y estructurado; la episódica conserva experiencias o resultados de interacciones anteriores; la procedimental almacenas estrategias de resolución de tareas.

Mecanismos de coordinación: permiten la comunicación entre agentes y el control de flujo de información. Entre ellos se incluyen procesos de handoff (transferencia de tareas entre agentes) y cueing (activación contextual de un agente según la situación).
Entorno de acción: capa donde el sistema ejecuta operaciones o interactúa con fuentes externas, como bases de datos, grafos de conocimiento o sistemas de usuario.

Esta organización modular y jerárquica diferencia a los sistemas agénticos de los AI Agents convencionales. Mientras que un agente aislado ejecuta funciones puntuales dentro de un contexto limitado, un sistema agéntico dispone de una estructura de control y memoria compartida que le permite razonar de forma iterativa, autoevaluar sus decisiones y coordinar múltiples procesos cognitivos. De este modo, los sistemas agénticos pueden asumir comportamientos más autónomos, sostenidos en la integración de datos estructurados, retroalimentación y planificación adaptativa.
\cite{Bandi2025} destacan además que los sistemas agénticos incorporan mecanismos de evaluación interna que les permiten verificar su propio desempeño, garantizando consistencia en las respuestas y alineación con objetivos predefinidos. Esta capacidad de autorregulación y aprendizaje continuo los posiciona como un marco conceptual distinto de los agentes individuales, extendiendo el alcance de la inteligencia artificial desde la ejecución de tareas hacia la gestión dinámica de conocimiento y razonamiento contextual.


5.2	Grafos de conocimiento


Los grafos de conocimiento representan información mediante una estructura compuesta por nodos y aristas dirigidas, expresadas generalmente como tripletas formadas por un sujeto, un predicado y un objeto. Este modelo permite describir relaciones semánticas de manera formal y navegable, facilitando el razonamiento sobre los vínculos existentes entre los elementos de un dominio. 

\begin{figure}[H]
\centering
  \includegraphics[scale=1]{Figuras/foto2_anteproyecto.png}
  \caption{Tomado de: Software Projects by the Smart Data Analytics (SDA) Research Group}
\vspace{-0.5cm}
\end{figure}

Según \cite{Sardina2024}, los grafos de conocimiento han adquirido relevancia en contextos de aprendizaje automático y razonamiento simbólico debido a su capacidad para combinar representación estructurada y análisis cuantitativo. A partir de ellos se derivan los modelos de incrustación de grafos de conocimiento (Knowledge Graph Embedding Models), que proyectan la estructura del grafo a un espacio vectorial continuo, preservando la información relacional. 

Estos modelos permiten realizar predicciones de enlaces, inferencias o recomendaciones basadas en la proximidad semántica de las entidades.

El desempeño de los modelos de incrustación depende en gran medida de las propiedades estructurales del grafo. Los estudios de Rossi et al. (2020) y Bonner et al. (2022) muestran que métricas como el grado de los nodos, la frecuencia de las relaciones y la cofrecuencia de entidades influyen directamente en la calidad del aprendizaje. Grafos con alta dispersión de grados tienden a favorecer la predicción de nodos con mayor conectividad, mientras que aquellos con baja densidad relacional dificultan la generalización.

\cite{Sardina2024} señalan que la estructura del grafo determina la forma en que los modelos de incrustación aprenden representaciones y que la topología influye incluso en la elección de hiperparámetros y en la estabilidad del proceso de entrenamiento. 
Estas observaciones resaltan la importancia de un diseño ontológico cuidadoso al construir un grafo de conocimiento, especialmente en dominios donde la consistencia semántica es esencial, como los documentos de investigación.

En el ámbito de la modelación conceptual, los grafos de conocimiento se apoyan en ontologías, que establecen clases, relaciones jerárquicas y restricciones lógicas. Las ontologías permiten definir el vocabulario de un dominio y especificar cómo los conceptos se relacionan entre sí, de modo que el grafo resultante no sea solo una red de datos, sino una representación formal del conocimiento.



5.3	Retrieval-Augmented Generation (RAG)


La generación aumentada por recuperación, o Retrieval-Augmented Generation (RAG), es una arquitectura híbrida que combina técnicas de recuperación de información con modelos de generación de lenguaje. Su principio central consiste en vincular la capacidad expresiva de los modelos generativos con fuentes externas de conocimiento, de modo que el texto producido esté respaldado por información factual y actualizada.

El esquema básico de RAG se compone de dos módulos. El primero es el recuperador, que localiza documentos o fragmentos relevantes desde una base de conocimiento o corpus externo. El segundo es el generador, que sintetiza la respuesta final a partir de la información obtenida. Este proceso permite que la generación de texto no dependa únicamente del conocimiento interno del modelo, mitigando los errores y las llamadas alucinaciones propias de los modelos entrenados de forma cerrada.

En sus primeras versiones, RAG utilizó métodos clásicos de recuperación basados en coincidencia de palabras clave, como BM25. Posteriormente, estos fueron sustituidos por técnicas de recuperación densa, en las que tanto las consultas como los documentos se representan en espacios vectoriales. Este cambio permitió realizar búsquedas semánticas más precisas, en las que la similitud se evalúa por significado y no por coincidencia léxica. Modelos posteriores integraron ambos procesos, entrenando conjuntamente el recuperador y el generador, lo que mejoró la coherencia entre la información recuperada y la respuesta producida.

A pesar de estos avances, los sistemas RAG presentan algunas limitaciones. Una de las más comunes es la fragmentación del contexto: los documentos recuperados pueden contener información parcial o redundante, lo que dificulta su integración en un texto coherente. También existen desafíos relacionados con la selección de fuentes confiables, la actualización del conocimiento y el costo computacional de realizar búsqueda y generación en cada consulta.

Con el fin de reducir estos problemas, surgieron estrategias complementarias conocidas como modelos reranker. Estos sistemas reordenan los resultados de la recuperación inicial, priorizando los fragmentos más relevantes antes de ser enviados al generador. De esta manera se mejora la precisión factual y se reduce el ruido en la información de entrada.

Una evolución posterior es GraphRAG, que introduce los grafos de conocimiento como base de recuperación. En lugar de operar sobre texto plano, GraphRAG organiza la información en nodos y relaciones que representan entidades, conceptos o hechos. Este enfoque permite realizar consultas estructuradas y obtener respuestas que reflejan relaciones semánticas complejas. El proceso incluye la construcción del grafo a partir de fuentes documentales, su indexación en una base semántica y la recuperación contextual de los nodos pertinentes, los cuales se combinan con el modelo generador.

El uso de grafos aporta ventajas importantes. Facilita la interpretación de los resultados, permite rastrear las fuentes de conocimiento utilizadas y posibilita un razonamiento de tipo multihop, en el que la información se obtiene a través de varios niveles de conexión entre entidades. Esta característica resulta especialmente útil en contextos donde los conceptos están interrelacionados de manera no lineal, como en los proyectos de investigación o los documentos metodológicos.

Más recientemente, han aparecido aproximaciones denominadas Agentic RAG, en las que la generación aumentada se integra dentro de una arquitectura agéntica. En estos sistemas, distintos agentes especializados se encargan de tareas específicas: unos recuperan información, otros verifican coherencia y otros sintetizan los resultados finales. Este modelo distribuye la carga cognitiva entre agentes cooperantes y permite incorporar mecanismos de memoria y reflexión, en los que el sistema evalúa y mejora sus propias respuestas antes de emitir la versión final.

En conjunto, las evoluciones de RAG muestran una transición desde la simple recuperación de texto hacia entornos más estructurados, conectados y autónomos. El paso por modelos reranker, GraphRAG y Agentic RAG refleja una tendencia hacia sistemas de generación que no solo producen lenguaje coherente, sino que también son capaces de razonar sobre el conocimiento, verificarlo y explicarlo de forma transparente.

5.4	Mecanismos de evaluación de sistemas agénticos


La evaluación de los sistemas agénticos basados en modelos de lenguaje ha evolucionado rápidamente, impulsada por la necesidad de medir no solo la calidad del resultado final, sino también la coherencia del razonamiento, la eficiencia en la planificación y la capacidad de adaptación en entornos dinámicos. Los enfoques recientes se organizan en cuatro grandes categorías que reflejan distintas dimensiones cognitivas: el razonamiento secuencial, el uso de herramientas y funciones, la autorreflexión, y la gestión de memoria.




Evaluación de razonamiento y planificación multi-etapa

La primera categoría se centra en medir la capacidad de los agentes para planificar, razonar en múltiples pasos y mantener la coherencia lógica en tareas complejas. Esta evaluación busca determinar si el sistema puede descomponer un problema en sub-tareas, realizar inferencias intermedias y alcanzar soluciones consistentes.

 Los marcos de referencia más utilizados se basan en tareas de razonamiento matemático, causal o lógico, y en entornos interactivos donde se requiere coordinar acciones sucesivas. En este tipo de evaluación se analizan indicadores como la corrección del plan, la capacidad de recuperación ante errores, la consistencia entre estados y la coherencia global del razonamiento. El objetivo no es únicamente validar la respuesta final, sino también la calidad del proceso que conduce a ella \citep{Asaf2025}.

Evaluación del uso de herramientas y funciones externas

Un segundo enfoque mide la competencia del agente para interactuar con herramientas, APIs o entornos de ejecución externos. Estas pruebas examinan la secuencia completa del proceso de function calling: desde el reconocimiento de intención y la selección de la herramienta adecuada, hasta la ejecución correcta y la integración de los resultados en la respuesta final. 

Las métricas habituales incluyen precisión en la selección de la herramienta, eficiencia en los parámetros utilizados y tasa de éxito en la ejecución. Este tipo de evaluación es esencial en sistemas agénticos que combinan modelos de lenguaje con módulos de cálculo, bases de conocimiento o servicios externos, ya que permite identificar si el agente actúa de forma autónoma y eficiente al conectar razonamiento simbólico y operaciones reales.

Evaluación de autorreflexión y mejora adaptativa

La tercera categoría corresponde a la evaluación de la autorreflexión, entendida como la capacidad del agente para analizar y corregir sus propios errores durante o después de la ejecución de una tarea. Este tipo de evaluación busca medir si el sistema puede detectar inconsistencias, ajustar sus estrategias y aprender de la retroalimentación. 

Los métodos más recientes, como los bancos de pruebas de reflexión cognitiva, descomponen el proceso en componentes como la actualización de creencias, la revisión de hipótesis, el razonamiento contrafactual y la metacognición. Estas pruebas resultan fundamentales en sistemas agénticos complejos, donde el éxito no depende solo de la ejecución, sino también de la capacidad del sistema para auto diagnosticarse y mejorar de forma continua sin supervisión humana directa.

Evaluación de memoria y persistencia contextual

Finalmente, los métodos centrados en la memoria analizan la habilidad del agente para retener, recuperar y utilizar información a lo largo del tiempo. La memoria se considera un componente esencial de la inteligencia agéntica, pues permite mantener coherencia entre interacciones, construir representaciones estables del entorno y vincular decisiones actuales con experiencias pasadas. 

Los mecanismos de evaluación en esta categoría miden aspectos como la precisión de recuperación, la persistencia de la información en contextos prolongados, la actualización eficiente de estados y la integración entre memoria semántica y episódica. En contextos documentales o académicos, estas pruebas permiten determinar si un sistema agéntico mantiene la coherencia conceptual al procesar grandes volúmenes de información y si puede razonar de manera acumulativa a lo largo de sesiones.
   

Evaluación LLM-as-a-Judge

El paradigma LLM-as-a-Judge utiliza un modelo de lenguaje de gran tamaño como evaluador de las salidas generadas por otros modelos o agentes. Este enfoque permite puntuar o clasificar respuestas según su coherencia, corrección factual o relevancia, simulando la valoración humana \citep{judge}.

Su principal ventaja es la escalabilidad, ya que posibilita evaluaciones masivas sin intervención manual. Sin embargo, un único juez puede introducir sesgos estilísticos o de preferencia hacia estructuras lingüísticas similares a las de su propio entrenamiento, lo que limita la imparcialidad de los resultados.
\newpage
\section{DISEÑO METODOLÓGICO}
\vspace{-0.5cm}

La presente investigación se desarrolla bajo un enfoque mixto, con predominio cuantitativo y carácter aplicado, complementado por una validación cualitativa experta. El propósito central es diseñar, implementar y evaluar un sistema agéntico copiloto basado en grafos de conocimiento, orientado a fortalecer la coherencia semántica y la consistencia contextual en la generación asistida de documentos metodológicos de investigación.

Dado que los sistemas agénticos dependen de modelos de lenguaje con componentes inherentes de aleatoriedad y posibles fenómenos de alucinación, su evaluación representa un desafío metodológico. En este tipo de arquitecturas no resulta suficiente emplear métricas tradicionales del aprendizaje automático, como Precisión, Recall o F1-Score, ya que estas no capturan dimensiones como coherencia discursiva, consistencia estructural o calidad contextual. Además, la solución propuesta introduce un nivel mayor de abstracción, pues no solo se evalúa el desempeño individual de los agentes, sino también su orquestación, la gestión de memoria contextual y la capacidad de razonamiento multi-hop orientada a objetivos documentales específicos.

En este sentido, el estudio se clasifica como experimental–aplicado, ya que integra el desarrollo tecnológico del sistema con una validación empírica controlada y un análisis cualitativo experto, garantizando coherencia entre formulación de hipótesis, diseño experimental, recolección de datos y análisis de resultados.

\textbf{Hipótesis principal:}

La integración de un sistema agéntico copiloto con un grafo de conocimiento mejora significativamente la coherencia y consistencia contextual en la generación asistida de documentos metodológicos.

\vspace{0.3cm}

En coherencia con esta hipótesis, se definen las siguientes variables:

\begin{table}[H]
\centering
\begin{tabular}{|p{4cm}|p{9cm}|}
\hline
\textbf{Tipo de variable} & \textbf{Descripción} \\ \hline
Independiente & Implementación del sistema agéntico con soporte de grafo de conocimiento. \\ \hline
Dependientes & Nivel de coherencia semántica, consistencia estructural y utilidad percibida. \\ \hline
De control & Tipo de documento, nivel de complejidad conceptual y extensión del texto generado. \\ \hline
\end{tabular}
\end{table}

El diseño adoptado es cuasi-experimental, con grupo único y mediciones pretest y postest. En la fase de pretest se evalúa la coherencia documental en textos generados sin asistencia del sistema. Posteriormente, en el postest, se analiza el mismo tipo de producción textual generada con apoyo del sistema agéntico. Esta comparación permite estimar el efecto de la variable independiente sobre las variables dependientes. De manera complementaria, se incorpora una validación cruzada mediante revisión experta.

El esquema general del diseño puede resumirse de la siguiente manera:

\begin{table}[H]
\centering
\begin{tabular}{|p{4cm}|p{9cm}|}
\hline
\textbf{Componente} &\textbf{ Descripción} \\ \hline
Pretest & Evaluación de coherencia en textos generados sin asistencia. \\ \hline
Intervención & Implementación del sistema agéntico con grafo de conocimiento. \\ \hline
Postest & Evaluación del mismo tipo de textos con asistencia del sistema. \\ \hline
Validación adicional & Revisión experta para contraste cualitativo. \\ \hline
\end{tabular}
\end{table}

La evaluación combina instrumentos automáticos y cualitativos, los cuales se sintetizan a continuación:

\begin{table}[H]
\centering
\begin{tabular}{|p{4cm}|p{9cm}|}
\hline
\textbf{Tipo de instrumento} & \textbf{Aplicación} \\ \hline
Métricas automáticas & Medición de coherencia semántica, completitud estructural y razonamiento multi-hop mediante esquemas tipo “LLM as Judge” en entorno MLOps. \\ \hline
Evaluación experta & Escala Likert (1–5) para valorar coherencia, pertinencia y utilidad. \\ \hline
Análisis estadístico & Análisis descriptivo y correlacional para identificar mejoras significativas entre pretest y postest. \\ \hline
\end{tabular}
\end{table}

El desarrollo metodológico del proyecto se organiza en cinco fases progresivas e integradas. En una primera fase se realiza el análisis conceptual y documental, mediante revisión sistemática de estructuras metodológicas y modelos de coherencia narrativa, lo que permite identificar patrones semánticos y dependencias conceptuales. 

En la segunda fase se aborda el modelado semántico y la construcción del grafo de conocimiento, formalizando la ontología mediante estándares como OWL y RDF, implementándola en una base de datos especializada y validando su consistencia estructural.

Posteriormente se diseña la arquitectura agéntica, definiendo los módulos funcionales asociados a lectura, verificación, razonamiento, navegación y gestión de contexto, así como los mecanismos de interacción y orquestación con el grafo.

En la cuarta fase se desarrolla el prototipo funcional e integra el sistema en un entorno controlado, realizando pruebas técnicas preliminares orientadas a verificar estabilidad y coherencia narrativa.

Finalmente, se ejecuta la evaluación experimental híbrida, combinando métricas automáticas y validación experta para determinar el impacto del sistema en términos de coherencia, consistencia y utilidad percibida.

En conjunto, este diseño metodológico mantiene coherencia entre objetivos, hipótesis, procedimientos y criterios de validación, permitiendo evaluar de manera sistemática la viabilidad técnica y el aporte funcional del sistema propuesto.


\begin{sidewaystable}
\subsection{Cronograma}
\centering
\renewcommand{\arraystretch}{1.2}
\footnotesize
\begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}X|*{8}{c|}}
\hline
\rowcolor{gray!25}
\textbf{Actividad} & \textbf{M1} & \textbf{M2} & \textbf{M3} & \textbf{M4} & \textbf{M5} & \textbf{M6} & \textbf{M7} & \textbf{M8} \\
\hline

% ---------------- FASE I ----------------
\multicolumn{9}{|>{\columncolor{gray!15}}l|}{\textbf{Fase I – Análisis conceptual y documental}} \\
\hline

Revisión de estructuras documentales metodológicas y modelos de coherencia 
& \cellcolor{blue!30} & & & & & & & \\

Identificación de patrones semánticos y dependencias conceptuales 
& \cellcolor{blue!30} & & & & & & & \\

Construcción de la taxonomía base y ontología preliminar 
& & \cellcolor{blue!30} & & & & & & \\
\hline

% ---------------- FASE II ----------------
\multicolumn{9}{|>{\columncolor{gray!15}}l|}{\textbf{Fase II – Modelado semántico y grafo de conocimiento}} \\
\hline

Diseño del modelo ontológico (OWL/RDF) 
& & \cellcolor{green!30} & & & & & & \\

Implementación inicial del grafo en base de datos especializada 
& & \cellcolor{green!30} & \cellcolor{green!30} & \cellcolor{green!30} & & & & \\

Validación estructural y semántica del modelo 
& & & \cellcolor{green!30} & \cellcolor{green!30} & & & & \\
\hline

% ---------------- FASE III ----------------
\multicolumn{9}{|>{\columncolor{gray!15}}l|}{\textbf{Fase III – Arquitectura agéntica y módulos cognitivos}} \\
\hline

Diseño modular de agentes cognitivos (lectura, verificación, razonamiento)
& & & & \cellcolor{orange!40} & & & & \\

Definición de flujos de interacción entre agentes y grafo 
& & & & \cellcolor{orange!40} & & & & \\

Documentación técnica y diagramas UML 
& & & \cellcolor{orange!40} & \cellcolor{orange!40} & \cellcolor{orange!40} & & & \\
\hline

% ---------------- FASE IV ----------------
\multicolumn{9}{|>{\columncolor{gray!15}}l|}{\textbf{Fase IV – Implementación del prototipo funcional}} \\
\hline

Desarrollo del sistema agéntico copiloto 
& & & & \cellcolor{purple!30} & \cellcolor{purple!30} & \cellcolor{purple!30} & \cellcolor{purple!30} & \cellcolor{purple!30} \\

Integración con el grafo de conocimiento 
& & & & & \cellcolor{purple!30} & \cellcolor{purple!30} & \cellcolor{purple!30} & \\
\hline

% ---------------- FASE V ----------------
\multicolumn{9}{|>{\columncolor{gray!15}}l|}{\textbf{Fase V – Evaluación y validación experimental híbrida}} \\
\hline

Pruebas técnicas de coherencia y consistencia narrativa 
& & & & & & & \cellcolor{red!30} & \cellcolor{red!30} \\

Implementación y ejecución de pruebas multi-hop y validación contextual automática 
& & & & & & \cellcolor{red!30} & \cellcolor{red!30} & \\

Evaluación experta mediante encuestas y observación controlada 
& & & & & & & & \cellcolor{red!30} \\

Análisis comparativo de desempeño y utilidad 
& & & & & & & & \cellcolor{red!30} \\

Consolidación de resultados y redacción del informe final 
& & \cellcolor{red!30} & \cellcolor{red!30} & \cellcolor{red!30} & \cellcolor{red!30} & \cellcolor{red!30} & \cellcolor{red!30} & \cellcolor{red!30} \\
\hline

\end{tabularx}


\caption{Cronograma general del proyecto (8 meses)}
\end{sidewaystable}
\newpage
\subsection{Resultados Esperados}
\vspace{-0.5cm}

El desarrollo metodológico propuesto permitirá obtener una serie de resultados progresivos y verificables que se corresponden directamente con los objetivos específicos definidos y las fases metodológicas planteadas. Cada fase aporta productos concretos que, en conjunto, evidencian el logro del objetivo general de diseñar y evaluar un sistema agéntico copiloto basado en grafos de conocimiento.

\textbf{Fase I. Análisis conceptual y documental:}

Como resultado de esta etapa se espera disponer de un mapa conceptual y semántico que describa las estructuras, dependencias y relaciones entre los componentes de los documentos de investigación. Este producto se materializará en una taxonomía de coherencia documental que servirá como insumo para el modelado del grafo de conocimiento. Adicionalmente, se generará un mapa conceptual con las metodologías más representativas de redacción metodológica y sus vínculos semánticos.

\textbf{Fase II.  Modelado semántico y diseño del grafo de conocimiento:}

El resultado central de esta fase será un modelo semántico-ontológico formalizado que represente las relaciones conceptuales identificadas en la fase anterior. Este modelo se implementará como un grafo de conocimiento funcional, construido en un una base de datos de grafos (por ejemplo, Neo4j o RDF/OWL), validado mediante consultas Cypher y revisión semántica. El grafo actuará como memoria contextual estructurada, permitiendo la representación explícita del conocimiento y las dependencias entre secciones de los documentos metodológicos. 

\textbf{Fase III. Diseño de la arquitectura agéntica:}

En esta fase se espera obtener una arquitectura agéntica cognitiva, compuesta por módulos especializados de lectura, análisis, verificación y navegación documental, capaces de interactuar con el grafo de conocimiento. El resultado tangible será un modelo arquitectónico documentado, expresado mediante diagramas UML y un BPMN adaptado, que detalle los procesos de comunicación entre agentes y su rol dentro del ecosistema de co-creación documental.
\newpage
\textbf{Fase IV. Implementación del prototipo funcional:}

El resultado esperado será un prototipo operativo del sistema agéntico copiloto, que integre los módulos cognitivos y el grafo de conocimiento en un entorno de experimentación controlado. Este prototipo demostrará la capacidad del sistema para generar, actualizar y verificar contenido contextual dentro de proyectos de investigación. Su desarrollo se acompañará de documentación técnica, guías de instalación y evidencias de funcionamiento (capturas, logs, datasets de prueba y reportes de desempeño).

\textbf{Fase V. Evaluación y validación híbrida:}

Finalmente, se espera obtener un informe de evaluación integral que combine resultados cuantitativos y cualitativos. En el componente experimental se generarán métricas objetivas sobre coherencia semántica, consistencia narrativa y razonamiento multi-hop, mientras que en el componente cualitativo se recogerán percepciones expertas sobre utilidad, pertinencia y aplicabilidad del sistema en la co-creación de documentos. 
Cabe aclarar que debido a la naturaleza generativa de los modelos base, se espera una implementación siguiendo practicas recientes de MLOPS o AgentOps, mediante un proceso iterativo con énfasis en encontrar la evaluación mínima enfocada en el propósito de este proyecto. Es decir, no se pretende llegar a un nivel de evaluación de entorno de producción, puesto que es un prototipo.
Los resultados permitirán identificar fortalezas, limitaciones y oportunidades de mejora del prototipo, consolidando su validez metodológica y su contribución práctica al campo de la inteligencia artificial aplicada a la documentación científica.


\newpage
\section{RECURSOS Y ASPECTOS ECONÓMICOS}
\vspace{-0.5cm}
\begin{table}[H]
\centering
\footnotesize
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.15}

\begin{tabularx}{\textwidth}{|p{2.8cm}|X|c|c|c|c|r|}
\hline
\rowcolor{azulUAO}
\color{white}\textbf{Concepto} &
\color{white}\textbf{Descripción} &
\multicolumn{4}{c|}{\color{white}\textbf{Tipo de financiación}} &
\color{white}\textbf{Costo Total} \\ \cline{3-6}

\rowcolor{azulUAO}
 & &
\color{white}\textbf{UAO Ef.} &
\color{white}\textbf{UAO Esp.} &
\color{white}\textbf{Propia Ef.} &
\color{white}\textbf{Propia Esp.} &
\\
\hline

1. Personal & Director del proyecto (5 h/semana) &  & 32.000.000 &  &  & 32.000.000 \\
 & Investigador (15 h/semana) &  &  &  & 48.000.000 & 48.000.000 \\
\hline

2. Recursos Tecnológicos & Servicios de nube (Azure) &  &  &  & 960.000 & 960.000 \\
 & Servicios modelos lenguaje (IA/Tokens) &  &  &  & 500.000 & 500.000 \\
 & Licenciamientos (Neo4J) &  &  &  & 1.560.000 & 1.560.000 \\
 & Office 365 &  & 400.000 &  &  & 400.000 \\
 & Documentación digital (papers, libros) &  &  &  & 300.000 & 300.000 \\
\hline

3. Equipos & Sistema almacenamiento y cómputo &  &  &  & 2.000.000 & 2.000.000 \\
 & Servicios de impresión (encuestas) &  &  &  & 250.000 & 250.000 \\
\hline

4. Materiales & Gastos de papelería &  &  &  & 100.000 & 100.000 \\
\hline

5. Imprevistos & Generales (1\%) &  &  &  & 860.700 & 860.700 \\
\hline

\rowcolor{azulUAO2}
\multicolumn{6}{|r|}{\textbf{COSTO TOTAL}} & \textbf{86.930.700} \\
\hline

\end{tabularx}

\caption{Recursos y aspectos económicos del proyecto}
\end{table}
Los recursos propuestos para esta investigación, corresponden mayoritariamente a gastos de nube, debido a la necesidad de usar recursos como modelos de lenguaje, despliegue de recursos de software en nube.
Por otro lado, se incluyen las horas de acompañamiento del Director del proyecto con una dedicación de 5 horas semanales, por su apoyo metodológico que obedecen un tipo de proyecto de modalidad de profundización.

Para las últimas actividades de evaluación cualitativa, se contempla la aplicación de encuestas y participación de otros docentes y expertos en el área académica, que corresponde a la justificación de los demás materiales relacionados en la tabla.
\newpage
\renewcommand{\refname}{REFERENCIAS}
\addcontentsline{toc}{section}{REFERENCIAS}
% si tiene el archivo .bib descomente las siguientes líneas y comente el entorno thebibliography
\bibliographystyle{apalike}
\bibliography{TuArchivo}

Ejemplo de como citar:

La neurociencia ha contribuido de manera significativa al entendimiento de la base neural de la toma de decisiones, que a menudo es considerada como un problema demasiado amplio para ser tratado \citep{Amaral00}. Amaral describe los primeros avances en la investigaci\'on de los mecanismos neuronales de la toma de decisiones y presenta una imagen del procesamiento neuronal en las regiones prefrontales que es relevante para la toma de decisiones complejas en seres humanos. \cite{Bentley09} sugieren que la\citep{Vaswani2017} conectividad de los ganglios basales es ideal para la selecci\'on de acciones \'optimas para estados cognitivos y de contexto dados. Ellos proponen un modelo a nivel de sistemas de los ganglios basales que intenta cerrar la brecha entre la anatom\'{i}a y la funci\'on autom\'atica de la toma de decisiones. Otras investigaciones que involucran los ganglios basales en la toma de decisiones fueron presentadas en \citep{Alysson06,Audi96,Serre05}.

Juli\'an Hurtado-L\'opez, David F. Ram\'{i}rez-Moreno and Terrence J. Sejnowski. (2017). Decision-making neural circuits mediating social behaviors: An attractor network model. \textit{Journal of Computational Neuroscience}, 43(2):127-142 (\url{http://dx.doi.org/10.1007/s10827-017-0654-8}).

%\begin{thebibliography}{99}
%\vspace{-0.5cm}
%\bibitem{Nombre1} Autor, "Título del Articulo," \textit{Título de la revista}, vol., no., p. Mes, Año.
%\bibitem{Nombre2} Autor, \textit{Título del libro}, vol., ed., Lugar de publicación: Editorial, p.  Año.
%\end{thebibliography}
Para elaborar las referencias de acuerdo a los parámetros de la Universidad se recomienda revisar las Guías CRAI.

Debe relacionar el principal material bibliográfico utilizado para estructurar la propuesta priorizando artículos científicos en inglés, documentos gubernamentales y fuentes confiables.

Se debe listar según formato de la norma APA o IEEE vigente, el apoyo bibliográfico que sirvió de apoyo para la elaboración del anteproyecto.

Es necesario que la norma APA o IEEE se aplique con rigurosidad. Se recomienda el uso de gestores bibliográficos como Mendeley o Zotero, etc. para las normas APA.

\newpage
\section*{ANEXOS}
\vspace{-0.5cm}
\addcontentsline{toc}{section}{ANEXOS}
Los Anexos son documentos o elementos que complementan el cuerpo del trabajo y que se relacionan, directa o indirectamente, con la investigación, tales como facturas, cd, normas, matrices, cronograma etc.\par 
Los anexos deben ir numerados con letras.\par 
Este capítulo es opcional, si lo utiliza: inserte los títulos como los títulos de las tablas y figuras pero se enumeran con letras.\par Estos títulos van justificados y con mayúscula inicial.

\newpage

{
\extrarowheight = -0.3ex
\renewcommand{\arraystretch}{1.8}

\begin{table}[H]
    \centering
    \caption{} \vspace{5mm}
    \textbf{Tabla con Títulos en las columnas} \vspace{7mm}
   
        \begin{tabular}{cccc}
        \hline
        Titulo1 & Titulo2 & Titulo3 & Titulo4  \\
        \hline
            150        & 210       & 130        & 1 \\
            1        & 1        & 1        & 1 \\
            1        & 1        & 1        & 1 \\
        \hline
        \end{tabular}
    \label{TablaI}
\end{table}}

AGREGANDO UNA FIGURA
\begin{figure}[H]
\centering
  \includegraphics[scale=1]{Figuras/buzz}
  \caption{Escriba aquí el nombre de la figura y si es de otro autor coloque el número de referencia}
\vspace{-0.5cm}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[scale=1]{Figuras/TG}
  \caption{Escriba aquí el nombre de la figura y si es de otro autor coloque el número de referencia}
\vspace{-0.5cm}
\end{figure}


AGREGAR VARIAS FIGURAS AGRUPADAS

\begin{figure}[H]
     \centering
     \begin{subfigure}{0.3\textwidth} % Define el ancho de la subfigura
         \centering
         \includegraphics[scale=1]{Figuras/fig1.png}
         \caption{Nombre fig1} % Mueve la leyenda aquí
         \label{fig1}
     \end{subfigure}
     \hfill % Espacio horizontal flexible
     \begin{subfigure}{0.3\textwidth}
         \centering
         \includegraphics[scale=1]{Figuras/fig2.png}
         \caption{Nombre fig2}
         \label{fig2}
     \end{subfigure}
     \hfill
     \begin{subfigure}{0.3\textwidth}
         \centering
         \includegraphics[scale=1]{Figuras/fig3.png}
         \caption{Nombre fig3}
         \label{fig3}
     \end{subfigure}
     \caption{Tres gráficas} % Leyenda principal
     \label{Tres gráficas}
\vspace{-0.5cm}
\end{figure}



La din\'amica de la nueva red es modelada por el sistema din\'amico introducido por las ecuaciones \eqref{ComplexM1}-\eqref{ComplexM5} como sigue.
\begin{align}
	\tau_1\frac{dx_1}{dt}&=-x_1+f_1(w_{11}x_1-w_{12}x_2+L_1),\label{ComplexM1}\\
	\tau_2\frac{dx_2}{dt}&=-x_2+f_2(-w_{21}x_1-w_{22}x_2+L_2),\label{ComplexM2}\\
	\tau_3\frac{dx_3}{dt}&=-x_3+f_3(w_{32}x_2+w_{33}x_3-w_{34}x_4-w_{35}x_5),\label{ComplexM3}\\
	\tau_4\frac{dx_4}{dt}&=-x_4+f_4(w_{42}x_2-w_{43}x_3+w_{44}x_4-w_{45}x_5),\label{ComplexM4}\\ 
	\tau_5\frac{dx_5}{dt}&=-x_5+f_5(-w_{51}x_1+w_{53}x_3-w_{54}x_4+w_{55}x_5).\label{ComplexM5}
\end{align}
\end{document}