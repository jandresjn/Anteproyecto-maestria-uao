@article{Alysson06, 
title={Generation of neuronal variability and complexity}, 
number={7097}, 
journal={Nature}, 
author={Muotri, Alysson R and Gage, Fred H}, 
volume={441},
year={2006}, 
pages={1087--1093}
}

@book{Amaral00,
    author = {Amaral, D.G.},
    pages = {337--348},
    publisher = {In: Principles of Neural Science, 4th Edition (ER Kandel, JH Schwartz, TM Jessell, Eds.)},
    title = {The functional organization of perception and movement},
    address = {New York: McGraw-Hill},
		year = {2000}
}

@inbook{Audi96, 
    address = {Oxford},
    author = {Audi, Robert},
    booktitle = {Moral knowledge?: new readings in moral epistemology},
    pages = {101--136},
    publisher = {Oxford University Press},
    title = {{Intuitionism, pluralism, and the foundations of ethics}},
    year = {1996}
}

@incollection{Bentley09,
title = "Neural Coding of Spatial Representations ",
editor = "Editor-in-Chief:  Larry R. Squire",
booktitle = "Encyclopedia of Neuroscience ",
publisher = "Academic Press",
edition = "",
address = "Oxford",
year = "2009",
pages = "117--122",
author = "N.M. Bentley and E. Salinas"
}

@techreport{Serre05,
     author =   "Serre, Thomas and Kouh, Minjoon and Cadieu, Charles and Knoblich, Ulf and Kreiman, Gabriel and Poggio, Tomaso",
      title =   "{A Theory of Object Recognition: Computations and Circuits in the Feedforward Path of the Ventral Stream in Primate Visual Cortex}",
      year =   "2005",
      language =   "english",
institution =   "Ft. Belvoir Defense Technical Information Center",
     date =   "December 2005"}
@article{Ding2025,
   abstract = {Representing domain knowledge extracted from unstructured texts using knowledge graphs supports knowledge reasoning, enabling the extraction of accurate factual information and the generation of interpretable results. However, reasoning with knowledge graphs is challenging due to their complex logical structures, which require deep semantic understanding and the ability to address uncertainties with common sense. The rapid development of large language models makes them an option for solving this problem, with good complementary capabilities regarding the determinacy of knowledge graph reasoning. However, the use of large language models for knowledge graph reasoning also has challenges, including structural understanding challenges and the balance of semantic density sparsity. This study proposes a domain knowledge graph reasoning method based on a large model prompt learning metapath (DKGM-path), discussing how to use large models for the preliminary induction of reasoning paths and completing reasoning on knowledge graphs based on iterative queries. The method has made significant progress on several public reasoning question answering benchmark datasets, demonstrating multi-hop reasoning capabilities based on knowledge graphs. It utilizes structured data interfaces to achieve accurate and effective data access and information processing and can intuitively show the reasoning process, with good interpretability.},
   author = {Ruidong Ding and Bin Zhou},
   doi = {10.3390/ELECTRONICS14051012},
   issn = {2079-9292},
   issue = {5},
   journal = {Electronics 2025, Vol. 14, Page 1012},
   keywords = {LLM reasoning,domain knowledge reasoning,machine learning,prompt learning},
   month = {3},
   pages = {1012},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Enhancing Domain-Specific Knowledge Graph Reasoning via Metapath-Based Large Model Prompt Learning},
   volume = {14},
   url = {https://www.mdpi.com/2079-9292/14/5/1012/htm https://www.mdpi.com/2079-9292/14/5/1012},
   year = {2025}
}
@article{Zhang2025,
   abstract = {As a core technology of structured semantic networks, knowledge graphs significantly enhance the semantic understanding and reasoning capabilities of intelligent search engines. This paper systematically analyzes the applications of knowledge graphs in scenarios such as entity search, complex question answering, and related recommendations. It explores their technical implementation paths and validates their effectiveness through typical cases (Google Knowledge Graph, Baidu Zhixin). The aim of this paper is to study how knowledge graphs empower intelligent search engines, analyze their technical challenges and development directions, and look ahead to the future trends of the integration of knowledge graphs with large models and multi-modal technologies.},
   author = {Cizhen Zhang and Yan Wang},
   doi = {10.3233/FAIA250448},
   isbn = {9781643685991},
   issn = {18798314},
   journal = {Frontiers in Artificial Intelligence and Applications},
   keywords = {Intelligent Search Engine,Knowledge Graph,Multi-hop Reasoning,Semantic Network},
   month = {6},
   pages = {330-336},
   publisher = {IOS Press},
   title = {Application of Knowledge Graphs in Intelligent Search Engines},
   volume = {407},
   url = {https://ebooks.iospress.nl/doi/10.3233/FAIA250448},
   year = {2025}
}
@inbook{Mohamed2025,
   abstract = {Knowledge Graphs (KGs) are becoming an essential tool in the organization, linkage, and analysis of complex data across various domains. By structuring information as entities and their interrelationships, KGs enhance data integration and pro-vide advanced capabilities such as reasoning, question-answering, and real-time decision-making. This paper explores methodologies for building and maintaining static and dynamic knowledge graphs, focusing on their applications in fields like virtual assistants, recommendation systems, autonomous systems, and AI-driven decision-making. The study emphasizes the growing significance of automation tools such as Named Entity Recognition (NER) and relationship extraction and addresses challenges in balancing automation with accuracy in KG construction. Furthermore, the transformation of static knowledge graphs into dynamic, continuously updating systems is discussed, showcasing their potential to revolutionize real-world applications by integrating ever-evolving datasets. In this context, dynamic KGs excel in domains that require real-time updates, making them invaluable for climate monitoring, autonomous vehicles, and production fault detection systems. This study provides insights into the methodologies and tools that can ensure high-quality KG creation, the challenges of real-time data integration, and how KGs contribute to advancing AI capabilities in data-rich environments. © 2025, IGI Global Scientific Publishing.},
   author = {Saher M. Mohamed and Abdelrahman Yasser Saeed and Kirollos Saleh Farah and Shahenda Hatem Mohamed and Abdelrahman Mahmoud Lotfy and Ghada Khoriba and Kareem Ayman Rizk and Tamer Arafa},
   doi = {10.4018/979-8-3693-7117-6.ch005},
   isbn = {9798369371190},
   booktitle = {Advanced Research Trends in Sustainable Solutions, Data Analytics, and Security},
   month = {1},
   pages = {99-146},
   publisher = {IGI Global},
   title = {Knowledge Graphs: The Future of Data Integration and Insightful Discovery},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/105006957612?origin=resultslist},
   year = {2025}
}
@article{Luo2025,
   abstract = {Logical rules are essential for uncovering the logical connections between relations, which could improve reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs to prompt LLMs to generate logical rules. To refine the generated rules, a rule ranking module estimates the rule quality by incorporating facts from existing KGs. Last, the ranked rules can be used to conduct reasoning over KGs. ChatRule is evaluated on five large-scale KGs, showing the effectiveness and scalability of our method.},
   author = {Linhao Luo and Jiaxin Ju and Bo Xiong and Yuan Fang Li and Gholamreza Haffari and Shirui Pan},
   doi = {10.1007/978-981-96-8173-0_25},
   isbn = {9789819681723},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science},
   keywords = {Knowledge Graph,Large Language Model,Logical Rule Mining},
   pages = {314-325},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning},
   volume = {15871 LNCS},
   year = {2025}
}
@article{Acharya2025,
   abstract = {Agentic AI, an emerging paradigm in artificial intelligence, refers to autonomous systems designed to pursue complex goals with minimal human intervention. Unlike traditional AI, which depends on structured instructions and close oversight, Agentic AI demonstrates adaptability, advanced decision-making capabilities and self-sufficiency, enabling it to operate dynamically in evolving environments. This survey thoroughly explores the foundational concepts, unique characteristics, and core methodologies driving the development of Agentic AI. We examine its current and potential applications across various fields, including healthcare, finance, and adaptive software systems, emphasizing the advantages of deploying agentic systems in real-world scenarios. The paper also addresses the ethical challenges posed by Agentic AI, proposing solutions for goal alignment, resource constraints, and environmental adaptability. We outline a framework for safely and effectively integrating Agentic AI into society, highlighting the need for further research on ethical considerations to ensure beneficial societal impacts. This survey serves as a comprehensive introduction to Agentic AI, guiding researchers, developers, and policymakers in engaging with its transformative potential responsibly and creatively.  © 2013 IEEE.},
   author = {Deepak Bhaskar Acharya and Karthigeyan Kuppan and B. Divya},
   doi = {10.1109/ACCESS.2025.3532853},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Agentic AI,adaptability,autonomous systems,ethical AI,governance frameworks,human-AI collaboration},
   pages = {18912-18936},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Agentic AI: Autonomous Intelligence for Complex Goals - A Comprehensive Survey},
   volume = {13},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85216361734?origin=scopusAI},
   year = {2025}
}
@article{Feng2025,
   abstract = {Background: Knowledge graphs and large language models (LLMs) are key tools for biomedical knowledge integration and reasoning, facilitating structured organization of scientific articles and discovery of complex semantic relationships. However, current methods face challenges: knowledge graph construction is limited by complex terminology, data heterogeneity, and rapid knowledge evolution, while LLMs show limitations in retrieval and reasoning, making it difficult to uncover cross-document associations and reasoning pathways. Results: We propose a pipeline that uses LLMs to construct a Biomedical Stratified Knowledge Graph (BioStrataKG) from large-scale articles and builds the Biomedical Cross-Document Question Answering Dataset (BioCDQA) to evaluate latent knowledge retrieval and multihop reasoning. We then introduce Integrated and Progressive Retrieval-Augmented Reasoning (IP-RAR) to enhance retrieval accuracy and knowledge reasoning. IP-RAR maximizes information recall through integrated reasoning-based retrieval and refines knowledge via progressive reasoning-based generation, using self-reflection to achieve deep thinking and precise contextual understanding. Experiments show that IP-RAR improves document retrieval F1 score by 20% and answer generation accuracy by 25% over existing methods. Conclusions: The IP-RAR helps doctors efficiently integrate treatment evidence to inform the development of personalized medication plans and enables researchers to analyze advancements and research gaps, accelerating the hypothesis generation phase of scientific discovery and decision-making. © The Author(s) 2025. Published by Oxford University Press on behalf of GigaScience.},
   author = {Yichun Feng and Jiawei Wang and Ruikun He and Lu Zhou and Yixue Li},
   doi = {10.1093/gigascience/giaf109},
   issn = {2047217X},
   journal = {GigaScience},
   keywords = {deep thinking,knowledge graph,knowledge mining,large language model,retrieval-augmented generation},
   pmid = {40971592},
   publisher = {Oxford University Press},
   title = {A retrieval-augmented knowledge mining method with deep thinking LLMs for biomedical research and clinical support},
   volume = {14},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/105016667527?origin=scopusAI},
   year = {2025}
}
@article{Li2023,
   abstract = {Knowledge graph question answering (Q &A) aims to answer questions through a knowledge base (KB). When using a knowledge base as a data source for multihop Q &A, knowledge graph Q &A needs to obtain relevant entities, their relationships and the correct answer, but often the correct answer cannot be obtained through the reasoning path because of absent relationships. Currently, using pre-trained language models (PLM) and knowledge graphs (KG) has a good effect on complex problems. However, challenging problems remain; the relationships between problems and candidate entities need to be better represented, and joint reasoning must be performed in the relationship graph based on problems and entities. To solve these problems, we expand the relational graph by adding tail entities to the list of preselected entities through reverse relations and then add the processed problems and entities to the problem subgraph. To perform inference on a relational graph, we design an attention-based neural network module. To calculate the loss of the model’s inference process nodes, we use a modified Euclidean distance function as the loss function. To evaluate our model, we conducted experiments on the WebQSP and CWQ datasets, and the model obtained state-of-the-art results in both the KB-full and KB-half settings. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
   author = {Fengying Li and Hongfei Huang and Rongsheng Dong},
   doi = {10.1007/978-3-031-44216-2_28},
   isbn = {9783031442155},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Knowledge graphs,Neural networks,Question answering},
   pages = {340-351},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Efficient Question Answering Based on Language Models and Knowledge Graphs},
   volume = {14257 LNCS},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85174601293?origin=scopusAI},
   year = {2023}
}
@article{Wang2025,
   abstract = {With the explosive growth of digitized information, traditional document retrieval techniques face significant bottlenecks in dealing with complex semantic association and multi-hop inference tasks. To solve this problem, this paper proposes a knowledge graph-based agent collaboration framework (KG-Agent), which integrates dynamic knowledge graph construction and agent reasoning mechanism to achieve deep understanding of documents and cross-modal knowledge fusion. KG-Agent framework innovatively designs a document-driven dynamic graph construction process, combining GPT-4o semantic parsing, multimodal entity disambiguation and Neo4j graph database technology to transform unstructured documents into structured semantic networks. In the reasoning mechanism, the agent dynamically plans the retrieval path of knowledge graph through reinforcement learning strategy, and solves the problem of complex logic chain breakage in legal and medical fields by using the collaborative optimization of symbolic rules and vectorized semantics. Experiments verify its practical value in knowledge-intensive scenarios. © 2025 SPIE.},
   author = {Yingjie Wang},
   doi = {10.1117/12.3071493},
   isbn = {9781510692190},
   issn = {1996756X},
   journal = {Proceedings of SPIE - The International Society for Optical Engineering},
   month = {7},
   pages = {123},
   publisher = {SPIE-Intl Soc Optical Eng},
   title = {Deep reasoning and retrieval of documents by agents based on knowledge graphs},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/105014196943?origin=scopusAI},
   year = {2025}
}
@article{Khorashadizadeh2023,
   abstract = {Knowledge graphs can represent information about the real-world using entities and their relations in a structured and semantically rich manner and they enable a variety of downstream applications such as question-answering, recommendation systems, semantic search, and advanced analytics. However, at the moment, building a knowledge graph involves a lot of manual effort and thus hinders their application in some situations and the automation of this process might benefit especially for small organizations. Automatically generating structured knowledge graphs from a large volume of natural language is still a challenging task and the research on sub-tasks such as named entity extraction, relation extraction, entity and relation linking, and knowledge graph construction aims to improve the state of the art of automatic construction and completion of knowledge graphs from text. The recent advancement of foundation models with billions of parameters trained in a self-supervised manner with large volumes of training data that can be adapted to a variety of downstream tasks has helped to demonstrate high performance on a large range of Natural Language Processing (NLP) tasks. In this context, one emerging paradigm is in-context learning where a language model is used as it is with a prompt that provides instructions and some examples to perform a task without changing the parameters of the model using traditional approaches such as fine-tuning. This way, no computing resources are needed for re-training/fine-tuning the models and the engineering effort is minimal. Thus, it would be beneficial to utilize such capabilities for generating knowledge graphs from text. In this paper, grounded by several research questions, we explore the capabilities of foundation models such as ChatGPT to generate knowledge graphs from the knowledge it captured during pre-training as well as the new text provided to it in the prompt. The paper provides a qualitative analysis of a set of example outputs generated by a foundation model with the aim of knowledge graph construction and completion. The results demonstrate promising capabilities. Furthermore, we discuss the challenges and next steps for this research work. © 2023 CEUR-WS. All rights reserved.},
   author = {Hanieh Khorashadizadeh and Nandana Mihindukulasooriya and Sanju Tiwari and Jinghua Groppe and Sven Groppe},
   journal = {CEUR Workshop Proceedings},
   title = {Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85168818600?origin=scopusAI},
   year = {2023}
}
@article{Tian2022,
   abstract = {The knowledge graph (KG) that represents structural relations among entities has become an increasingly important research field for knowledge-driven artificial intelligence. In this survey, a comprehensive review of KG and KG reasoning is provided. It introduces an overview of KGs, including representation, storage, and essential technologies. Specifically, it summarizes several types of knowledge reasoning approaches, including logic rules-based, representation-based, and neural network-based methods. Moreover, this paper analyzes the representation methods of knowledge hypergraphs. To effectively model hyper-relational data and improve the performance of knowledge reasoning, a three-layer knowledge hypergraph model is proposed. Finally, it analyzes the advantages of three-layer knowledge hypergraphs through reasoning and update algorithms which could facilitate future research. © 2022, Journal of Electronic Science and Technology. All Rights Reserved.},
   author = {Ling Tian and Xue Zhou and Yan Ping Wu and Wang Tao Zhou and Jin Hao Zhang and Tian Shu Zhang},
   doi = {10.1016/j.jnlest.2022.100159},
   issn = {2666223X},
   issue = {2},
   journal = {Journal of Electronic Science and Technology},
   keywords = {Knowledge graph (kg),Knowledge graph applications,Knowledge hypergraph,Knowledge reasoning},
   publisher = {KeAi Communications Co.},
   title = {Knowledge Graph and Knowledge Reasoning: A Systematic Review},
   volume = {20},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85138487360?origin=resultslist},
   year = {2022}
}
@article{Wang2025,
   abstract = {Recent years, multi-hop reasoning has been widely studied for knowledge graph (KG) reasoning due to its efficacy and interpretability. However, previous multi-hop reasoning approaches are subject to two primary shortcomings. First, agents struggle to learn effective and robust policies at the early phase due to sparse rewards. Second, these approaches often falter on specific datasets like sparse knowledge graphs, where agents are required to traverse lengthy reasoning paths. To address these problems, we propose a multi-hop reasoning model with dual agents based on hierarchical reinforcement learning (HRL), which is named FULORA. FULORA tackles the above reasoning challenges by eFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks on the simplified knowledge graph to provide stage-wise hints for the low-level agent walking on the original knowledge graph. In this framework, the low-level agent optimizes a value function that balances two objectives: (1) maximizing return, and (2) integrating efficient guidance from the high-level agent. Experiments conducted on three real-word knowledge graph datasets demonstrate that FULORA outperforms RL-based baselines, especially in the case of long-distance reasoning. Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
   author = {Zijian Wang and Bin Wang and Haifeng Jing and Huayu Li and Hongbo Dou},
   doi = {10.1609/aaai.v39i12.33398},
   isbn = {157735897X},
   issn = {23743468},
   issue = {12},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   month = {4},
   pages = {12818-12826},
   publisher = {Association for the Advancement of Artificial Intelligence},
   title = {Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration},
   volume = {39},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/105003946578?origin=scopusAI},
   year = {2025}
}
@article{Buehler2025,
   abstract = {We present an agentic, autonomous graph expansion framework that iteratively structures and refines knowledge in situ. Unlike conventional knowledge graph construction methods relying on static extraction or single-pass learning, our approach couples a reasoning-native large language model with a continually updated graph representation. At each step, the system actively generates new concepts and relationships, merges them into a global graph, and formulates subsequent prompts based on its evolving structure. Through this feedback-driven loop, the model organizes information into a scale-free network characterized by hub formation, stable modularity, and bridging nodes that link disparate knowledge clusters. Over hundreds of iterations, new nodes and edges continue to appear without saturating, while centrality measures and shortest path distributions evolve to yield increasingly distributed connectivity. Our analysis reveals emergent patterns-such as the rise of highly connected "hub" concepts and the shifting influence of "bridge" nodes-indicating that agentic, self-reinforcing graph construction can yield open-ended, coherent knowledge structures. Applied to materials design problems, we present compositional reasoning experiments by extracting node-specific and synergy-level principles to foster genuinely novel knowledge synthesis, yielding cross-domain ideas that transcend rote summarization and strengthen the framework's potential for open-ended scientific discovery. We discuss other applications in scientific discovery and outline future directions for enhancing scalability and interpretability.},
   author = {Markus J Buehler},
   keywords = {Artificial,Category,Engineering,Graph,Intelligence ·,Isomorphisms ·,Language,Materials,Materiomics ·,Modeling ·,Reasoning ·,Science ·,Theory ·},
   title = {Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks A Preprint},
   year = {2025}
}
@article{Abdellah2024,
   abstract = {Legal documents are characterized by their com¬plexity and interconnectivity which pose a challenge in discovering and retrieving knowledge. Effective interrogation and reasoning of such documents necessitate a representation framework conducive to logical analysis and decision-making. Knowledge Graphs emerge as a leading solution for structuring and connecting information within legal documents, offering a systematic approach to handle complex legal content. In this paper, we present a comprehensive pipeline designed to transform legal documents, the Algerian Official Journal in our case, into knowledge graphs, for both French and Arabic editions. The proposed pipeline includes data collection, entities and relationships identification, and entities disambiguation. The built knowledge graphs can be used in many use cases, such as, information retrieval, question answering, and recommendation.},
   author = {Hamouda Sidhoum Abdellah and Mataoui M'Hamed and Sebbak Faouzi and Ouazene Aymen and Hussine Fedoua},
   doi = {10.1109/AICT61888.2024.10740457},
   isbn = {9798350387537},
   journal = {18th IEEE International Conference on Application of Information and Communication Technologies, AICT 2024},
   keywords = {Algerian official journal,Entity disambiguation,Knowledge graphs,Legal documents,NER},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Transforming Legal Documents into Knowledge Goldmines: Application on the Algerian Official Journal},
   year = {2024}
}
@article{Khorashadizadeh2023,
   abstract = {Knowledge graphs can represent information about the real-world using entities and their relations in a structured and semantically rich manner and they enable a variety of downstream applications such as question-answering, recommendation systems, semantic search, and advanced analytics. However, at the moment, building a knowledge graph involves a lot of manual effort and thus hinders their application in some situations and the automation of this process might benefit especially for small organizations. Automatically generating structured knowledge graphs from a large volume of natural language is still a challenging task and the research on sub-tasks such as named entity extraction, relation extraction, entity and relation linking, and knowledge graph construction aims to improve the state of the art of automatic construction and completion of knowledge graphs from text. The recent advancement of foundation models with billions of parameters trained in a self-supervised manner with large volumes of training data that can be adapted to a variety of downstream tasks has helped to demonstrate high performance on a large range of Natural Language Processing (NLP) tasks. In this context, one emerging paradigm is in-context learning where a language model is used as it is with a prompt that provides instructions and some examples to perform a task without changing the parameters of the model using traditional approaches such as fine-tuning. This way, no computing resources are needed for re-training/fine-tuning the models and the engineering effort is minimal. Thus, it would be beneficial to utilize such capabilities for generating knowledge graphs from text. In this paper, grounded by several research questions, we explore the capabilities of foundation models such as ChatGPT to generate knowledge graphs from the knowledge it captured during pre-training as well as the new text provided to it in the prompt. The paper provides a qualitative analysis of a set of example outputs generated by a foundation model with the aim of knowledge graph construction and completion. The results demonstrate promising capabilities. Furthermore, we discuss the challenges and next steps for this research work. © 2023 CEUR-WS. All rights reserved.},
   author = {Hanieh Khorashadizadeh and Nandana Mihindukulasooriya and Sanju Tiwari and Jinghua Groppe and Sven Groppe},
   journal = {CEUR Workshop Proceedings},
   title = {Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85168818600?origin=scopusAI},
   year = {2023}
}
@article{Khorashadizadeh2023,
   abstract = {Knowledge graphs can represent information about the real-world using entities and their relations in a structured and semantically rich manner and they enable a variety of downstream applications such as question-answering, recommendation systems, semantic search, and advanced analytics. However, at the moment, building a knowledge graph involves a lot of manual effort and thus hinders their application in some situations and the automation of this process might benefit especially for small organizations. Automatically generating structured knowledge graphs from a large volume of natural language is still a challenging task and the research on sub-tasks such as named entity extraction, relation extraction, entity and relation linking, and knowledge graph construction aims to improve the state of the art of automatic construction and completion of knowledge graphs from text. The recent advancement of foundation models with billions of parameters trained in a self-supervised manner with large volumes of training data that can be adapted to a variety of downstream tasks has helped to demonstrate high performance on a large range of Natural Language Processing (NLP) tasks. In this context, one emerging paradigm is in-context learning where a language model is used as it is with a prompt that provides instructions and some examples to perform a task without changing the parameters of the model using traditional approaches such as fine-tuning. This way, no computing resources are needed for re-training/fine-tuning the models and the engineering effort is minimal. Thus, it would be beneficial to utilize such capabilities for generating knowledge graphs from text. In this paper, grounded by several research questions, we explore the capabilities of foundation models such as ChatGPT to generate knowledge graphs from the knowledge it captured during pre-training as well as the new text provided to it in the prompt. The paper provides a qualitative analysis of a set of example outputs generated by a foundation model with the aim of knowledge graph construction and completion. The results demonstrate promising capabilities. Furthermore, we discuss the challenges and next steps for this research work. © 2023 CEUR-WS. All rights reserved.},
   author = {Hanieh Khorashadizadeh and Nandana Mihindukulasooriya and Sanju Tiwari and Jinghua Groppe and Sven Groppe},
   journal = {CEUR Workshop Proceedings},
   title = {Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85168818600?origin=scopusAI},
   year = {2023}
}
@article{Han2024,
   abstract = {With the escalating complexity in production scenarios, vast amounts of production information are retained within enterprises in the industrial domain. Probing questions of how to meticulously excavate value from complex document information and establish coherent information links arise. In this work, we present a framework for knowledge graph construction in the industrial domain, predicated on knowledge-enhanced document-level entity and relation extraction. This approach alleviates the shortage of annotated data in the industrial domain and models the interplay of industrial documents. To augment the accuracy of named entity recognition, domain-specific knowledge is incorporated into the initialization of the word embedding matrix within the bidirectional long short-term memory conditional random field (BiLSTM-CRF) framework. For relation extraction, this paper introduces the knowledge-enhanced graph inference (KEGI) network, a pioneering method designed for long paragraphs in the industrial domain. This method discerns intricate interactions among entities by constructing a document graph and innovatively integrates knowledge representation into both node construction and path inference through TransR. On the application stratum, BiLSTM-CRF and KEGI are utilized to craft a knowledge graph from a knowledge representation model and Chinese fault reports for a steel production line, specifically SPOnto and SPFRDoc. The F1 value for entity and relation extraction has been enhanced by 2% to 6%. The quality of the extracted knowledge graph complies with the requirements of real-world production environment applications. The results demonstrate that KEGI can profoundly delve into production reports, extracting a wealth of knowledge and patterns, thereby providing a comprehensive solution for production management. © Higher Education Press 2024.},
   author = {Zhulin Han and Jian Wang},
   doi = {10.1007/s42524-023-0273-1},
   issn = {20960255},
   issue = {1},
   journal = {Frontiers of Engineering Management},
   keywords = {BiLSTM-CRF,document-level relation extraction,graph inference,industrial,knowledge graph construction},
   month = {3},
   pages = {143-158},
   publisher = {Higher Education Press Limited Company},
   title = {Knowledge enhanced graph inference network based entity-relation extraction and knowledge graph construction for industrial domain},
   volume = {11},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85184392628?origin=scopusAI},
   year = {2024}
}
@article{Rajeev2025,
   abstract = {Disconnected data silos within enterprises obstruct the extraction of actionable insights, diminishing efficiency in areas such as product development, client engagement, meeting preparation, and analytics-driven decision-making. This paper introduces a framework that uses large language models (LLMs) to unify various data sources into a comprehensive, activity-centric knowledge graph. The framework automates tasks such as entity extraction, relationship inference, and semantic enrichment, enabling advanced querying, reasoning, and analytics across data types like emails, calendars, chats, documents, and logs. Designed for enterprise flexibility, it supports applications such as contex-tual search, task prioritization, expertise discovery, personalized recommendations, and advanced analytics to identify trends and actionable insights. Experimental results demonstrate its success in the discovery of expertise, task management, and data-driven decision making. By integrating LLMs with knowledge graphs, this solution bridges disconnected systems and delivers intelligent analytics-powered enterprise tools.},
   author = {Gen Ai Research and Althire Ai and San Francisco and Usa Rajeev@althire Ai and Kumar Ishan},
   isbn = {9798331524807},
   keywords = {Activity Graph,Enterprise Intelligence,Entity extraction,Index Terms-Knowledge graph,LLM,Relation extraction},
   title = {LLM-Powered Knowledge Graphs for Enterprise Intelligence and Analytics 1 st Rajeev Kumar 3 rd Harishankar Kumar 4 th Abhinandan Singla},
   url = {https://arxiv.org/pdf/2503.07993v1},
   year={2025}
}
@article{Wang2025,
   abstract = {The construction of medical knowledge graphs(KGs) structures complex medical data to support precise clinical decision-making and knowledge discovery. A core challenge in building medical KGs is effectively representing and processing complex clinical data. Existing triple-based medical knowledge representation methods often fail to fully capture and express the complexity of the data, particularly when dealing with higher-order relationships involving multiple entities. Additionally, the current”Attribute-Concept-Event” three-layer knowledge organization framework shows limitations in representing procedural knowledge in medical scenarios, falling short of the hierarchical and dynamic requirements of evidence-based medicine. To address these issues, we propose a four-layer medical knowledge organization method based on hypergraph theory. By incorporating hypergraph theory and a narrative layer into the KG, we provide a more flexible and dynamic framework for representing complex clinical information. Based on this approach, we construct a four-layer KG, RJUA-HKG, using real QA clinical data from urology as an example. Experiments show that, compared to traditional KGs, RJUA-HKG significantly reduces relational complexity and retrieval time while accurately capturing changes in diagnostic and treatment procedures. © 2024 Copyright held by the owner/author(s).},
   author = {Qi Wang and Qiyuan Li and Chao Gao and Haijiang Liu and Fangfang Xu and Jinguang Gu},
   doi = {10.1145/3706890.3706998},
   isbn = {9798400717826},
   journal = {Proceedings of 2024 5th International Symposium on Artificial Intelligence for Medicine Science, ISAIMS 2024},
   keywords = {Knowledge graph,Knowledge hypergraph theory,Knowledge organization,Medical knowledge management mechanism},
   month = {1},
   pages = {627-633},
   publisher = {Association for Computing Machinery, Inc},
   title = {A Medical Knowledge Management Mechanism with Knowledge Hypergraph Theory},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85217825067?origin=scopusAI},
   year = {2025}
}
@article{Bandi2025,
   abstract = {Agentic AI systems are a recently emerged and important approach that goes beyond traditional AI, generative AI, and autonomous systems by focusing on autonomy, adaptability, and goal-driven reasoning. This study provides a clear review of agentic AI systems by bringing together their definitions, frameworks, and architectures, and by comparing them with related areas like generative AI, autonomic computing, and multi-agent systems. To do this, we reviewed 143 primary studies on current LLM-based and non-LLM-driven agentic systems and examined how they support planning, memory, reflection, and goal pursuit. Furthermore, we classified architectural models, input–output mechanisms, and applications based on their task domains where agentic AI is applied, supported using tabular summaries that highlight real-world case studies. Evaluation metrics were classified as qualitative and quantitative measures, along with available testing methods of agentic AI systems to check the system’s performance and reliability. This study also highlights the main challenges and limitations of agentic AI, covering technical, architectural, coordination, ethical, and security issues. We organized the conceptual foundations, available tools, architectures, and evaluation metrics in this research, which defines a structured foundation for understanding and advancing agentic AI. These findings aim to help researchers and developers build better, clearer, and more adaptable systems that support responsible deployment in different domains. © 2025 by the authors.},
   author = {Ajay Bandi and Bhavani Kongari and Roshini Naguru and Sahitya Pasnoor and Sri Vidya Vilipala},
   doi = {10.3390/fi17090404},
   issn = {19995903},
   issue = {9},
   journal = {Future Internet},
   keywords = {adaptive ai,agentic ai,ai agents,ai frameworks and architectures,ai systems,chatGPT,ethical ai,goal-directed ai,langchain,metaGPT,multi-agents},
   month = {9},
   publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
   title = {The Rise of Agentic AI: A Review of Definitions, Frameworks, Architectures, Applications, Evaluation Metrics, and Challenges},
   volume = {17},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/105017420897?origin=scopusAI},
   year = {2025}
}
@article{Bai2024,
   abstract = {Knowledge graph (KG) is a key component of artificial intelligence. In recent years, many large-scale knowledge graphs have been produced and put into practical applications. At present, researchers have proposed many methods to reason facts that do not exist in knowledge graphs using the existing information. However, most traditional reasoning methods lack interpretability, and cannot get the reasoning paths. Therefore, the multi-hop path reasoning method of knowledge graph has gradually become a hot spot. This method finds the next relations through the reinforcement learning agent, gets the whole path, and scores the path. Although these multi-hop path reasoning methods make the reasoning method interpretable, these multi-hop path reasoning methods focus on the choice of relations, ignoring the importance of entities in the path reasoning process. Moreover, with the development of the Temporal Knowledge Graph (TKG), traditional multi-hop path reasoning methods cannot effectively process time information. To solve these problems, a multi-hop path reasoning method of temporal knowledge graph based on multi-agent reinforcement learning is proposed, which is named MA-TPath. MA-TPath uses two agents to perform relation selection and entity selection iteratively. Meanwhile, considering the diversity of temporal reasoning paths, we propose a new type of reward function. In MA-TPath, two agents employ the Long Short-Term Memory Networks (LSTM) to capture current results from the environment and output the corresponding action vectors to the environment through activation functions. Experimentally, MA-TPath outperforms all existing models in 4 out of 4 indicators on the YAGO dataset, 3 out of 4 indicators on the GDETL-5 dataset and the ICEWS-250 dataset, and 1 out of 4 indicators on the ICEWS05–15 dataset. Analysis of the temporal reasoning path indicates that MA-TPath not only surpasses other state-of-the-art reasoning methods over four public temporal knowledge graph datasets but provides rationality for results. © 2024 Elsevier B.V.},
   author = {Luyi Bai and Mingzhuo Chen and Qianwen Xiao},
   doi = {10.1016/j.asoc.2024.111727},
   issn = {15684946},
   journal = {Applied Soft Computing},
   keywords = {Multi-agent,Multi-hop reasoning,Reinforcement learning,Temporal knowledge graph},
   month = {7},
   publisher = {Elsevier Ltd},
   title = {Multi-hop temporal knowledge graph reasoning with multi-agent reinforcement learning},
   volume = {160},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85192854268?origin=scopusAI},
   year = {2024}
}
@article{Yun2024,
   abstract = {Large language models are widely applied in educational scenarios. Students can engage in personalized and interactive learning through intelligent learning assistants installed on various devices. Among these applications, integrating large language models (LLMs) with knowledge graphs to achieve complex reasoning is a key issue. Traditional methods often solve multi-hop query problems based on individual technologies, leading to insufficient accuracy and comprehensiveness in answering complex questions. This paper proposes an intelligent agent framework called K12-Agent, which uses retrieval-enhanced generation, fine-tuning of LLMs integrated with knowledge graphs, and collaborative reasoning to enhance the initiative of the agent in interactions with students. Compared to traditional methods, K12-Agent has improved the accuracy by 15% and the recall rate by 13% when facing complex student questions. Additionally, K12-Agent is more adaptable to the expression methods of younger students, making it more user-friendly.},
   author = {Xiao Yun},
   doi = {10.1109/ISPCEM64498.2024.00036},
   isbn = {9798331528676},
   journal = {Proceedings - 2024 4th International Signal Processing, Communications and Engineering Management Conference, ISPCEM 2024},
   keywords = {K12,agent,complex reasoning,knowledge graph,large language model},
   pages = {168-174},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A Complex Reasoning Framework for Intelligent Learning Assistant Based on Large Language Model and Knowledge Graph},
   year = {2024}
}
@article{Li2024,
   abstract = {In the realm of computational knowledge representation, Knowledge Graph Reasoning (KG-R) stands at the forefront of facilitating sophisticated inferential capabilities across multifarious domains. The quintessence of this research elucidates the employment of reinforcement learning (RL) strategies, notably the REINFORCE algorithm, to navigate the intricacies inherent in multi-hop KG-R. This investigation critically addresses the prevalent challenges introduced by the inherent incompleteness of Knowledge Graphs (KGs), which frequently results in erroneous inferential outcomes, manifesting as both false negatives and misleading positives. By partitioning the Unified Medical Language System (UMLS) benchmark dataset into rich and sparse subsets, we investigate the efficacy of pre-trained BERT embeddings and Prompt Learning methodologies to refine the reward shaping process. This approach not only enhances the precision of multi-hop KG-R but also sets a new precedent for future research in the field, aiming to improve the robustness and accuracy of knowledge inference within complex KG frameworks. Our work contributes a novel perspective to the discourse on KG reasoning, offering a methodological advancement that aligns with the academic rigor and scholarly aspirations of the Natural journal, promising to invigorate further advancements in the realm of computational knowledge representation.},
   author = {Chen Li and Haotian Zheng and Yiping Sun and Cangqing Wang and Liqiang Yu and Che Chang and Xinyu Tian and Bo Liu},
   keywords = {Index Terms-Knowledge Graph Reasoning,Reinforcement Learning,Reward Shaping,Transfer Learning},
   month = {3},
   title = {Enhancing Multi-Hop Knowledge Graph Reasoning through Reward Shaping Techniques},
   url = {https://arxiv.org/pdf/2403.05801v1},
   year = {2024}
}
@article{Sumukh2024,
   abstract = {It is increasingly difficult for legal practitioners to effectively extract useful information and insights from the vast number of legal papers. Traditional manual document analysis methods are time-consuming, error-prone, and unable to uncover underlying relationships and patterns in legal texts. We propose a novel approach that combines intelligent document analysis techniques with knowledge graphs (KG) in order to enhance the efficacy and efficiency of processing legal documents. In this study, we present a comprehensive framework for natural language processing (NLP)-based automated extraction and structuring of legal information from a large corpus of documents. The knowledge graph that serves as a rich semantic representation of legal ideas and their interactions is incorporated into our method along with these strategies. We offer enhanced reasoning and inference skills to find latent linkages and deliver deeper insights into legal texts by embedding legal knowledge into the KG. According to the early findings, activities related to document comprehension, such as entity extraction, relationship extraction, and legal concept identification, are much more accurate and efficient when intelligent analytic approaches are combined with KG-based representation. Advanced functions like automatic legal document summarizing, precedent recognition, and legal case similarity analysis are also made possible by the KG. By reducing the time and effort required to analyze documents while increasing the quality of the information obtained, the proposed framework has the potential to fundamentally alter how legal document analysis is done. The combination of intelligent procedures with KG-based representation equips legal practitioners with useful insights, speeds up the decision-making process, and makes it possible for them to better negotiate complicated legal environments. This work opens new possibilities for AI in the legal sector, paving the path for future advancements in intelligent legal document analysis. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
   author = {Sirmokadam Sumukh and Shahi Shashwat},
   doi = {10.1007/978-981-97-3245-6_28},
   isbn = {9789819732449},
   issn = {23673389},
   journal = {Lecture Notes in Networks and Systems},
   keywords = {Knowledge graphs,Legal document analysis,Legal domain ontology},
   pages = {417-425},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {A Framework for Analyzing Legal Documents by Leveraging Knowledge Graphs},
   volume = {998 LNNS},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85206218558?origin=scopusAI},
   year = {2024}
}
@article{Ren2022,
   abstract = {Knowledge graphs (KGs) capture knowledge in the form of head - relation - tail triples and are a crucial component in many AI systems. There are two important reasoning tasks on KGs: (1) single-hop knowledge graph completion, which involves predicting individual links in the KG; and (2), multi-hop reasoning, where the goal is to predict which KG entities satisfy a given logical query. Embedding-based methods solve both tasks by first computing an embedding for each entity and relation, then using them to form predictions. However, existing scalable KG embedding frameworks only support single-hop knowledge graph completion and cannot be applied to the more challenging multi-hop reasoning task. Here we present Scalable Multi-hOp REasoning (SMORE), the first general framework for both single-hop and multi-hop reasoning in KGs. Using a single machine SMORE can perform multi-hop reasoning in Freebase KG (86M entities, 338M edges), which is 1,500x larger than previously considered KGs. The key to SMORE's runtime performance is a novel bidirectional rejection sampling that achieves a square root reduction of the complexity of online training data generation. Furthermore, SMORE exploits asynchronous scheduling, overlapping CPU-based data sampling, GPU-based embedding computation, and frequent CPU - GPU IO. SMORE increases throughput (i.e., training speed) over prior multi-hop KG frameworks by 2.2x with minimal GPU memory requirements (2GB for training 400-dim embeddings on 86M-node Freebase) and achieves near linear speed-up with the number of GPUs. Moreover, on the simpler single-hop knowledge graph completion task SMORE achieves comparable or even better runtime performance to state-of-the-art frameworks on both single GPU and multi-GPU settings.  © 2022 ACM.},
   author = {Hongyu Ren and Hanjun Dai and Bo Dai and Xinyun Chen and Denny Zhou and Jure Leskovec and Dale Schuurmans},
   doi = {10.1145/3534678.3539405},
   isbn = {9781450393850},
   journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
   keywords = {knowledge graph embeddings,multi-hop reasoning,scalable system},
   month = {8},
   pages = {1472-1482},
   publisher = {Association for Computing Machinery},
   title = {SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive Knowledge Graphs},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85137146764?origin=scopusAI},
   year = {2022}
}
@article{Dess2025,
   abstract = {The rapid evolution of AI and the increased accessibility of scientific articles through open access marks a pivotal moment in research. AI-driven tools are reshaping how scientists explore, interpret, and contribute to the body of scientific knowledge, offering unprecedented opportunities. Nonetheless, a significant challenge remains: dealing with the overwhelming number of papers published every year. A promising solution is the use of knowledge graphs, which provide structured, interconnected, and formalized frameworks that improve the capabilities of AI systems to integrate information from the literature. This paper presents the last version of the Computer Science Knowledge Graph (CS-KG 2.0), an extensive knowledge base generated from 15 million research papers. CS-KG 2.0 describes 25 million entities linked by 67 million relationships, offering a nuanced representation of the scientific knowledge within the field of computer science. This innovative resource facilitates new research opportunities in key areas such as analysis and forecasting of research trends, hypothesis generation, smart literature search, automatic production of literature review, and scientific question-answering.},
   author = {Danilo Dessí and Francesco Osborne and Davide Buscaldi and Diego Reforgiato Recupero and Enrico Motta},
   doi = {10.1038/S41597-025-05200-8;SUBJMETA},
   issn = {20524463},
   issue = {1},
   journal = {Scientific Data },
   keywords = {Research data,Technology},
   month = {12},
   pages = {1-16},
   pmid = {40490472},
   publisher = {Nature Research},
   title = {CS-KG 2.0: A Large-scale Knowledge Graph of Computer Science},
   volume = {12},
   url = {https://www.nature.com/articles/s41597-025-05200-8},
   year = {2025}
}
@article{Wang2020,
   abstract = {An ongoing project explores the extent to which artificial intelligence (AI), specifically in the areas of natural language processing and semantic reasoning, can be exploited to facilitate the studies of science by deploying software agents equipped with natural language understanding capabilities to read scholarly publications on the web. The knowledge extracted by these AI agents is organized into a heterogeneous graph, called Microsoft Academic Graph (MAG), where the nodes and the edges represent the entities engaging in scholarly communications and the relationships among them, respectively. The frequently updated data set and a few software tools central to the underlying AI components are distributed under an open data license for research and commercial applications. This paper describes the design, schema, and technical and business motivations behind MAG and elaborates how MAG can be used in analytics, search, and recommendation scenarios. How AI plays an important role in avoiding various biases and human induced errors in other data sets and how the technologies can be further improved in the future are also discussed. © 2020 Kuansan Wang, Zhihong Shen, Chi-Yuan Huang, Chieh-Han Wu, Yuxiao Dong, and Anshul Kanakia.},
   author = {Kuansan Wang and Zhihong Shen and Chiyuan Huang and Chieh Han Wu and Yuxiao Dong and Anshul Kanakia},
   doi = {10.1162/qss_a_00021},
   issn = {26413337},
   issue = {1},
   journal = {Quantitative Science Studies},
   keywords = {Citation networks,Eigenvector centrality measure,Knowledge graph,Research assessments,Saliency ranking,Scholarly database},
   month = {2},
   pages = {396-413},
   publisher = {MIT Press Journals},
   title = {Microsoft academic graph: When experts are not enough},
   volume = {1},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/85090098906?origin=scopusAI},
   year = {2020}
}

@article{Paulose2025,
   abstract = {Generative AI and Agentic AI systems are revolutionizing the way organizations approach automation by enabling machines to autonomously perform complex tasks that traditionally required human intervention. These systems leverage large language models (LLMs) to process vast amounts of information, interpret complex workflows, and make decisions in real-time. Agentic AI frameworks, in particular, offer a new level of intelligence, allowing for dynamic, context-aware task execution across various industries. By integrating such advanced AI capabilities, businesses can automate decision-making processes and achieve unprecedented levels of efficiency and accuracy in handling routine and sophisticated tasks alike. This paper introduces SmartGenie, an Agentic AI CoPilot developed as part of the SmartOps intelligent automation platform. SmartGenie utilizes an LLM-based framework that is adaptable and easily integrated with autonomous automation scenarios. We present a use case where SmartGenie automates the handling of employee service requests for a financial client, autonomously responding to and resolving issues. This implementation resulted in significant improvements in request completion times, enhanced accuracy, and overall operational efficiency. These findings demonstrate the transformative potential of SmartGenie to drive quality and performance improvements in business-critical processes through the use of Agentic LLMs.},
   author = {Renjith Paulose and Vinod Neelanath and Milgy George},
   doi = {10.1109/ETIS64005.2025.10961403},
   isbn = {9798331507541},
   journal = {ETIS International Conference on Emerging Technologies for Intelligent Systems, ETIS 2025},
   keywords = {Agentic AI,Autonomous Automation,SmartGenie CoPilot,Workflow Orchestration},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Domain Agnostic Agentic AI: Enabling Autonomous Automation with SmartGenie CoPilot},
   year = {2025}
}
@article{Nan2020,
   abstract = {Document-level relation extraction requires integrating information within and across multiple sentences of a document and capturing complex interactions between inter-sentence entities. However, effective aggregation of relevant information in the document remains a challenging research question. Existing approaches construct static document-level graphs based on syntactic trees, co-references or heuristics from the unstructured text to model the dependencies. Unlike previous methods that may not be able to capture rich non-local interactions for inference, we propose a novel model that empowers the relational reasoning across sentences by automatically inducing the latent document-level graph. We further develop a refinement strategy, which enables the model to incrementally aggregate relevant information for multi-hop reasoning. Specifically, our model achieves an F1 score of 59.05 on a large-scale document-level dataset (DocRED), significantly improving over the previous results, and also yields new state-of-the-art results on the CDR and GDA dataset. Furthermore, extensive analyses show that the model is able to discover more accurate inter-sentence relations.},
   author = {Guoshun Nan and Zhijiang Guo and Ivan Sekulić and Wei Lu},
   doi = {10.18653/v1/2020.acl-main.141},
   isbn = {9781952148255},
   issn = {0736587X},
   journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
   month = {5},
   pages = {1546-1557},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Reasoning with Latent Structure Refinement for Document-Level Relation Extraction},
   url = {https://arxiv.org/pdf/2005.06312},
   year = {2020}
}
@article{Li2022,
   abstract = {Document-level relation extraction (Doc-level RE) is a more practical and challenging task, which provides a new perspective on obtaining factual knowledge from the more complex cross-sentence text. Recent Doc-level RE, based on pre-trained language models, uses graph neural networks to implicitly model relation reasoning in a document. However, it is not perfect that the model neglects explicit reasoning clues, leading to a weak ability and a lack of capability to model long-distance relationships. In this paper, we propose to explicitly model the heterogeneous affinity graph, HAG, including a mention graph (MG) and a coreference graph (CG). We first construct CG to cluster the expressions together as a coreference array. Then, MG and CG are incorporated to capture the reasoning clues from the adjacent affinity matrix. Moreover, HAG is aggregated into an isomorphic entity graph according to the noise suppression mechanism and RGCN. Finally, the classification is established on the normalized graph to infer the relations of entity pairs. Experimental results significantly outperform baselines by nearly 1.7% ∼ 2.0% in F1 on three public datasets, DocRED, DialogRE, and MPDD. We further conduct ablation experiments to demonstrate the effectiveness of the proposed approach.},
   author = {Rongzhen Li and Jiang Zhong and Zhongxuan Xue and Qizhu Dai and Xue Li},
   doi = {10.1016/J.KNOSYS.2022.109146},
   issn = {0950-7051},
   journal = {Knowledge-Based Systems},
   keywords = {Document-level relation extraction,Graph convolutional network,Relation reasoning},
   month = {8},
   pages = {109146},
   publisher = {Elsevier},
   title = {Heterogenous affinity graph inference network for document-level relation extraction},
   volume = {250},
   url = {https://www.sciencedirect.com/science/article/pii/S0950705122005706},
   year = {2022}
}
@article{Mathur2024,
   abstract = {Digital documents, such as PDFs, are vital in business workflows, enabling communication, documentation, and collaboration. Handling PDFs can involve navigating complex work-flows and numerous tools (e.g., comprehension, annotation, editing), which can be tedious and time-consuming for users. We introduce DocPi-lot, an AI-assisted document workflow Copilot system capable of understanding user intent and executing tasks accordingly to help users streamline their workflows. DocPilot undertakes intelligent orchestration of various tools through LLM prompting in four steps: (1) Task plan generation, (2) Task plan verification and self-correction, (3) Multi-turn User Feedback, and (4) Task Plan Execution via Code Generation and Error log-based Code Self-Revision. Our goal is to enhance user efficiency and productivity by simplifying and automating their document workflows with task delegation to DocPilot.},
   author = {Puneet Mathur and Alexa Siu and Varun Manjunatha and Tong Sun},
   pages = {232-246},
   title = {DocPilot: Copilot for Automating PDF Edit Workflows in Documents},
   volume = {3},
   year={2024}
}
@article{Liao2021,
   abstract = {Text coherence plays a key role in document quality assessment. Most existing text coherence methods only focus on similarity of adjacent sentences. However, local coherence exists in sentences with broader contexts and diverse rhetoric relations, rather than just adjacent sentences similarity. Besides, the highlevel text coherence is also an important aspect of document quality. To this end, we propose a hierarchical coherence model for document quality assessment. In our model, we implement a local attention mechanism to capture the location semantics, bilinear tensor layer for measure coherence and max-coherence pooling for acquiring high-level coherence. We evaluate the proposed method on two realistic tasks: news quality judgement and automated essay scoring.   Experimental results demonstrate the validity and superiority of our work.},
   author = {Dongliang Liao and Jin Xu and Gongfu Li and Yiru Wang},
   doi = {10.1609/AAAI.V35I15.17576},
   isbn = {9781713835974},
   issn = {2374-3468},
   issue = {15},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   keywords = {Text Classification & Sentiment Analysis},
   month = {5},
   pages = {13353-13361},
   publisher = {Association for the Advancement of Artificial Intelligence},
   title = {Hierarchical Coherence Modeling for Document Quality Assessment},
   volume = {35},
   url = {https://ojs.aaai.org/index.php/AAAI/article/view/17576},
   year = {2021}
}
@article{Pan2025,
   abstract = {Coherence is an important component of text quality assessment and plays an indispensable role in many natural language processing tasks, such as automated essay scoring, text translation, and generative text quality assessment. Most existing coherence evaluation methods focus on local coherence between adjacent sentences or on discourse coherence based on the document, lacking a comprehensive evaluation from multiple perspectives. To address these issues, a multi-perspective coherence assessment model for English texts (MPCA) has been proposed. The MPCA model includes a text semantic extraction module based on attention mechanisms, a text local coherence extraction module based on Bi-linear layers, and a text discourse coherence extraction module based on lightweight convolution (LCNN). It comprehensively evaluates the coherence of English texts from three perspectives: semantic consistency, local coherence, and discourse coherence. Experiments have shown that compared to baseline models, the MPCA model achieves optimal performance in terms of QWK values for coherence feature scores on eight subsets of the ASAP++ public English essay datasets, and reaches the best overall average QWK value of 72.15%, demonstrating the effectiveness of the MPCA model in the task of English text coherence assessment.},
   author = {Xiao Chen Pan and Yong Yang and Ge Ren},
   doi = {10.1109/AINIT65432.2025.11035868},
   isbn = {9798331522285},
   journal = {2025 IEEE 6th International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2025},
   keywords = {deep learning,multi-perspective evaluation,natural language processing,text coherence},
   pages = {1526-1532},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Multi-Perspective Coherence Assessment Method for English Texts},
   year = {2025}
}
@article{Chu2024,
   abstract = {An AI agent is an intelligent framework that can perceive, plan and decompose, perform actions, and reflect. The multi-agent mode is a distributed computing mode that collaborates to complete different tasks in a group of AI intelligent agent environments. After discussion, inspection, reasoning, and evaluation, accurate conclusions are drawn. Multi AI intelligent agents play a crucial role in enhancing the performance of large models. Research and optimization of multi-agent architecture provide more perspectives and insights for system architecture design. In network planning, there are various application scenarios for reviewing planning template documents. This paper studies a multi-agent architecture based on open-source large language models, which is applied to planning document templates and data review to enhance the efficiency of processing and analyzing.},
   author = {Weiyan Chu and Sitan Yin and Lei Huang and Ling Lin and Xiaodong Wang and Zhi Zhang and Hongwu Li},
   doi = {10.1109/IUCC65928.2024.00072},
   isbn = {979-8-3315-1199-9},
   journal = {2024 International Conference on Ubiquitous Computing and Communications (IUCC)},
   keywords = {framework,intelligent verification,multi-agent,paradigm,performance,verify-agent},
   month = {12},
   pages = {374-379},
   publisher = {IEEE Computer Society},
   title = {Verify-Agent: Large Language Model Multi-Agent for Intelligent Verification},
   year = {2024}
}
@article{Krayem2025,
   abstract = {This study presents MMA-RAG, a multi-modal, multi-agent Retrieval-Augmented Generation (RAG) system tailored for insurance document processing. Our approach addresses challenges posed by diverse, unstructured data such as scanned PDFs, tables, and handwritten...},
   author = {Ibrahim Krayem and Malak Ghourabi and Mohamad Al Assaad},
   doi = {10.1007/978-3-031-99965-9_13},
   isbn = {978-3-031-99965-9},
   issn = {2367-3389},
   journal = {Lecture Notes in Networks and Systems},
   keywords = {Insurance document processing,Multi-modal agents,Retrieval-Augmented Generation},
   pages = {196-209},
   publisher = {Springer, Cham},
   title = {MMA-RAG: Multi-Modal Agents for Insurance Document Processing with Retrieval-Augmented Generation},
   volume = {1554 LNNS},
   url = {https://link.springer.com/chapter/10.1007/978-3-031-99965-9_13},
   year = {2025}
}
@article{Khamis2025,
   abstract = {An AI agent is a goal-oriented autonomous computational entity that connects reasoning and action using large language models (LLMs) or Large Reasoning Models (LRMs), memory systems, and external tools to achieve contextually intelligent outcomes. An agentic AI system comprises and coordinates multiple specialized AI agents to achieve complex goals with minimal or no human supervision. In this paper, agentic AI systems are elucidated through a frictionless-parking scenario that illustrates core components of the system, namely the design of individual AI agents, their interaction mechanisms (handoff and cueing), and potential cooperation patterns (augmentative, integrative, and debative). This scenario provides an experimental test-bed for demonstrating how agentic AI can deliver context-aware, personalized services. A six-factor factorial experiment evaluates performance of the implemented AI agents across five user profiles, four GPT backbones, three entropy levels, three verbosity settings, three query complexities, and three prompt specificity levels. To guarantee that each agent’s recommendation is both plausible and constraint-compliant, the system combines guardrails, which reject or rewrite answers that violate user requirements, with Chain-of-Thought prompting that exposes intermediate reasoning steps for internal self-checks. Key metrics (agent’s response time or latency and lexical consistency) show that a lightweight gpt-4o-mini backbone and concise verbosity minimize latency, while medium prompt specificity and moderate query complexity optimize consistency. Decoding entropy influences stylistic diversity without significant latency costs but reduces consistency at high settings. User intent, particularly for creative or ambiguous profiles, drives variability. A SHAP analysis ranks model size, verbosity, and prompt specificity as top performance drivers.},
   author = {Alaa Khamis},
   doi = {10.1109/ACCESS.2025.3590264},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {AI agents,Agentic AI,large language models (LLMs),large reasoning models (LRMs),multi-agent system,parking,urban mobility},
   pages = {126052-126069},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Agentic AI Systems: Architecture and Evaluation Using a Frictionless Parking Scenario},
   volume = {13},
   year = {2025}
}
@article{Belcak2025,
   abstract = {Large language models (LLMs) are often praised for exhibiting near-human performance on a wide range of tasks and valued for their ability to hold a general conversation. The rise of agentic AI systems is, however, ushering in a mass of applications in which language models perform a small number of specialized tasks repetitively and with little variation. Here we lay out the position that small language models (SLMs) are sufficiently powerful, inherently more suitable, and necessarily more economical for many invocations in agentic systems, and are therefore the future of agentic AI. Our argumentation is grounded in the current level of capabilities exhibited by SLMs, the common architectures of agentic systems, and the economy of LM deployment. We further argue that in situations where general-purpose conversational abilities are essential, heterogeneous agentic systems (i.e., agents invoking multiple different models) are the natural choice. We discuss the potential barriers for the adoption of SLMs in agentic systems and outline a general LLM-to-SLM agent conversion algorithm. Our position 1 , formulated as a value statement, highlights the significance of the operational and economic impact even a partial shift from LLMs to SLMs is to have on the AI agent industry. We aim to stimulate the discussion on the effective use of AI resources and hope to advance the efforts to lower the costs of AI of the present day. Calling for both contributions to and critique of our position, we commit to publishing all such correspondence at research.nvidia.com/labs/lpr/slm-agents.},
   author = {Peter Belcak and Greg Heinrich and Shizhe Diao and Yonggan Fu and Xin Dong and Saurav Muralidharan and Yingyan Celine Lin and Pavlo Molchanov},
   keywords = {cs.AI},
   title = {Small Language Models are the Future of Agentic AI}
}
@article{Bonifazi2025,
   abstract = {Agentic AI and Large Language Models (LLMs) are transforming how language is understood and generated while reshaping decision-making, automation, and research practices. LLMs provide underlying reasoning capabilities, and Agentic AI systems use them to perform tasks through interactions with external tools, services, and Application Programming Interfaces (APIs). Based on a structured scoping review and thematic analysis, this study identifies that core challenges of LLMs, relating to security, privacy and trust, misinformation, misuse and bias, energy consumption, transparency and explainability, and value alignment, can propagate into Agentic AI. Beyond these inherited concerns, Agentic AI introduces new challenges, including context management, security, privacy and trust, goal misalignment, opaque decision-making, limited human oversight, multi-agent coordination, ethical and legal accountability, and long-term safety. We analyse the applications of Agentic AI powered by LLMs across six domains: education, healthcare, cybersecurity, autonomous vehicles, e-commerce, and customer service, to reveal their real-world impact. Furthermore, we demonstrate some LLM limitations using DeepSeek-R1 and GPT-4o. To the best of our knowledge, this is the first comprehensive study to integrate the challenges and applications of LLMs and Agentic AI within a single forward-looking research landscape that promotes interdisciplinary research and responsible advancement of this emerging field.},
   author = {Gianluca Bonifazi and Enrico Corradini and Michele Marchetti and Sarfraz Brohi and Qurat-Ul-Ain Mastoi and N Z Jhanjhi and Thulasyammal Ramiah Pillai},
   doi = {10.3390/A18080499},
   issn = {1999-4893},
   issue = {8},
   journal = {Algorithms 2025, Vol. 18, Page 499},
   keywords = {4o,Agentic AI,DeepSeek,GPT,R1,agent systems,and ethical challenges,future Agentic AI research,generation AI,large language models (LLMs),legal,multi,next,technical},
   month = {8},
   pages = {499},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {A Research Landscape of Agentic AI and Large Language Models: Applications, Challenges and Future Directions},
   volume = {18},
   url = {https://www.mdpi.com/1999-4893/18/8/499/htm https://www.mdpi.com/1999-4893/18/8/499},
   year = {2025}
}

@article{Sapkota2026,
   abstract = {Information fusion, in the context of the Generative AI era, must distinguish AI Agents from Agentic AI. This review critically distinguishes between AI Agents and Agentic AI, offering a structured, conceptual taxonomy, application mapping, and analysis of opportunities and challenges to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven and enabled by LLMs and LIMs for task-specific automation. Generative AI is positioned as a precursor providing the foundation, with AI agents advancing through tool integration, prompt engineering, and reasoning enhancements. We then characterize Agentic AI systems, which, in contrast to AI Agents, represent a paradigm shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and coordinated autonomy. Through a chronological evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both AI agents and agentic AI paradigms. Application domains enabled by AI Agents such as customer support, scheduling, and data summarization are then contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure, and propose targeted solutions such as ReAct loops, retrieval-augmented generation (RAG), automation coordination layers, and causal modeling. This work aims to provide a roadmap for developing robust, scalable, and explainable AI-driven systems.},
   author = {Ranjan Sapkota and Konstantinos I. Roumeliotis and Manoj Karkee},
   doi = {10.1016/j.inffus.2025.103599},
   issn = {15662535},
   journal = {Information Fusion},
   keywords = {AI agents,Agentic AI,Conceptual taxonomy,Context awareness,Multi-agent systems},
   month = {2},
   publisher = {Elsevier B.V.},
   title = {AI Agents vs. Agentic AI: A Conceptual taxonomy, applications and challenges},
   volume = {126},
   url = {http://arxiv.org/abs/2505.10468 http://dx.doi.org/10.1016/j.inffus.2025.103599},
   year = {2026}
}
@article{Peng2024,
   abstract = {Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable success in addressing the challenges of Large Language Models (LLMs) without necessitating retraining. By referencing an external knowledge base, RAG refines LLM outputs, effectively mitigating issues such as "hallucination", lack of domain-specific knowledge, and outdated information. However, the complex structure of relationships among different entities in databases presents challenges for RAG systems. In response, GraphRAG leverages structural information across entities to enable more precise and comprehensive retrieval, capturing relational knowledge and facilitating more accurate, context-aware responses. Given the novelty and potential of GraphRAG, a systematic review of current technologies is imperative. This paper provides the first comprehensive overview of GraphRAG methodologies. We formalize the GraphRAG workflow, encompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced Generation. We then outline the core technologies and training methods at each stage. Additionally, we examine downstream tasks, application domains, evaluation methodologies, and industrial use cases of GraphRAG. Finally, we explore future research directions to inspire further inquiries and advance progress in the field. In order to track recent progress in this field, we set up a repository at https://github.com/pengboci/GraphRAG-Survey. 1 Introduction The development of Large Language Models like GPT-4 [127], Qwen2 [184], and LLaMA [31] has sparked a revolution in the field of artificial intelligence, fundamentally altering the landscape of natural language processing. These models, built on Transformer [161] architectures and trained on diverse and extensive datasets, have demonstrated unprecedented capabilities in understanding, interpreting, and generating human language. The impact of these advancements is profound, stretching across various sectors including healthcare [103, 166, 203], finance [93, 125], and education [46, 169], where they facilitate more nuanced and efficient interactions between humans and machines. Despite their remarkable language comprehension and text generation capabilities, LLMs may exhibit limitations due to a lack of domain-specific knowledge, real-time updated information, and proprietary knowledge, which are outside LLMs' pre-training corpus. These gaps can lead to a phenomenon known as "hallucination" [61] where the model generates inaccurate or even fabricated information. Consequently, it is imperative to supplement LLMs with external knowledge to mitigate this problem. Retrieval-Augmented Generation (RAG) [34, 45, 59, 62, 178, 195, 202] emerged as a significant evolution, which aims to enhance the quality and relevance of generated content by integrating a retrieval component within the generation process. The essence of RAG lies in its ability to dynamically query a large text corpus to incorporate relevant factual knowledge into the responses generated by the underlying language models. This integration not only enriches the contextual depth of the responses but also ensures a higher degree of factual accuracy and specificity. RAG has gained widespread attention due to its exceptional performance and broad applications, becoming a key focus within the field. Although RAG has achieved impressive results and has been widely applied across various domains, it faces limitations in real-world scenarios: (1) Neglecting Relationships: In practice, textual content is not isolated but interconnected. Traditional RAG fails to capture significant structured relational knowledge that cannot be represented through semantic similarity alone. For instance, in a citation network where papers are linked by citation relationships, traditional RAG methods focus on finding the relevant papers based on the query but overlook important citation relationships between papers. (2) Redundant Information: RAG often recounts content in the form of textual snippets when concatenated as prompts. This makes context become excessively lengthy, leading to the "lost in the middle" dilemma [104]. (3) Lacking Global Information: RAG can only retrieve a subset of documents and fails to grasp global information comprehensively, and hence struggles with tasks such as Query-Focused Summarization (QFS). Graph Retrieval-Augmented Generation (GraphRAG) [32, 58, 119] emerges as an innovative solution to address these challenges. Unlike traditional RAG, GraphRAG retrieves graph elements containing relational knowledge pertinent to a given query from a pre-constructed graph database, as depicted in Figure 1. These elements may include nodes, triples, paths, or subgraphs, which are utilized to generate responses. GraphRAG considers the interconnections between texts, enabling a more accurate and comprehensive retrieval of relational information. Additionally, graph data, such as knowledge graphs, offer abstraction and summarization of textual data, thereby significantly shortening the length of the input text and mitigating concerns of verbosity. By retrieving subgraphs or graph communities, we can access comprehensive information to effectively address the QFS challenge by capturing the broader context and interconnections within the graph structure.},
   author = {Boci Peng and Yun Zhu and Yan Zhang and Xiaohe Bo and Yongchao Liu and Haizhou Shi and Chuntao Hong and Siliang Tang},
   doi = {XXXXXXX.XXXXXXX},
   isbn = {2408.08921v2},
   issue = {4},
   journal = {Journal of the ACM},
   keywords = {Graph Neural Networks,Graph Retrieval-Augmented Generation,Knowledge Graphs,Large Language Models},
   title = {Graph Retrieval-Augmented Generation: A Survey},
   volume = {37},
   url = {https://doi.org/XXXXXXX.XXXXXXX},
   year = {2024}
}
@article{Han2024,
   abstract = {Retrieval-augmented generation (RAG) is a powerful technique that enhances downstream task execution by retrieving additional information, such as knowledge, skills, and tools from external sources. Graph, by its intrinsic "nodes connected by edges" nature, encodes massive heterogeneous and relational information, making it a golden resource for RAG in tremendous real-world applications. As a result, we have recently witnessed increasing attention on equipping RAG with Graph, i.e., GraphRAG. However, unlike conventional RAG, where the retriever, generator, and external data sources can be uniformly designed in the neural-embedding space, the uniqueness of graph-structured data, such as diverse-formatted and domain-specific relational knowledge, poses unique and significant challenges when designing GraphRAG for different domains. Given the broad applicability, the associated design challenges, and the recent surge in GraphRAG, a systematic and up-to-date survey of its key concepts and techniques is urgently desired. Following this motivation, we present a comprehensive and up-to-date survey on GraphRAG. Our survey first proposes a holistic GraphRAG framework by defining its key components, including query processor, retriever, organizer, generator, and data source. Furthermore, recognizing that graphs in different domains exhibit distinct relational patterns and require dedicated designs, we review GraphRAG techniques uniquely tailored to each domain. Finally, we discuss research challenges and brainstorm directions to inspire cross-disciplinary opportunities. Our survey repository is publicly maintained at https://github.com/Graph-RAG/GraphRAG/.},
   author = {Haoyu Han and Yu Wang and Harry Shomer and Kai Guo and Jiayuan Ding and Yongjia Lei and Mahantesh Halappanavar and Ryan A. Rossi and Subhabrata Mukherjee and Xianfeng Tang and Qi He and Zhigang Hua and Bo Long and Tong Zhao and Neil Shah and Amin Javari and Yinglong Xia and Jiliang Tang},
   month = {12},
   title = {Retrieval-Augmented Generation with Graphs (GraphRAG)},
   url = {https://arxiv.org/pdf/2501.00309},
   year = {2024}
}
@article{Singh2025,
   abstract = {Large Language Models (LLMs) have revolutionized artificial intelligence (AI) by enabling human like text generation and natural language understanding. However, their reliance on static training data limits their ability to respond to dynamic, real time queries, resulting in outdated or inaccurate outputs. Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs by integrating real time data retrieval to provide contextually relevant and up-to-date responses. Despite its promise, traditional RAG systems are constrained by static workflows and lack the adaptability required for multistep reasoning and complex task management. Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these limitations by embedding autonomous AI agents into the RAG pipeline. These agents leverage agentic design patterns reflection, planning, tool use, and multiagent collaboration to dynamically manage retrieval strategies, iteratively refine contextual understanding, and adapt workflows to meet complex task requirements. This integration enables Agentic RAG systems to deliver unparalleled flexibility, scalability, and context awareness across diverse applications. This survey provides a comprehensive exploration of Agentic RAG, beginning with its foundational principles and the evolution of RAG paradigms. It presents a detailed taxonomy of Agentic RAG architectures, highlights key applications in industries such as healthcare, finance, and education, and examines practical implementation strategies. Additionally, it addresses challenges in scaling these systems, ensuring ethical decision making, and optimizing performance for real-world applications, while providing detailed insights into frameworks and tools for implementing Agentic RAG.},
   author = {Aditi Singh and Abul Ehtesham and Saket Kumar and Tala Talaei Khoei},
   keywords = {//githubcom/asinghcsu/AgenticRAG-Survey,https},
   month = {1},
   title = {Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG},
   url = {https://arxiv.org/pdf/2501.09136},
   year = {2025}
}
@article{Zhang2025,
   abstract = {Large language model (LLM) applications such as agents and domain-specific reasoning increasingly rely on context adaptation -- modifying inputs with instructions, strategies, or evidence, rather than weight updates. Prior approaches improve usability but often suffer from brevity bias, which drops domain insights for concise summaries, and from context collapse, where iterative rewriting erodes details over time. Building on the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context Engineering), a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies through a modular process of generation, reflection, and curation. ACE prevents collapse with structured, incremental updates that preserve detailed knowledge and scale with long-context models. Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and rollout cost. Notably, ACE could adapt effectively without labeled supervision and instead by leveraging natural execution feedback. On the AppWorld leaderboard, ACE matches the top-ranked production-level agent on the overall average and surpasses it on the harder test-challenge split, despite using a smaller open-source model. These results show that comprehensive, evolving contexts enable scalable, efficient, and self-improving LLM systems with low overhead.},
   author = {Qizheng Zhang and Changran Hu and Shubhangi Upasani and Boyuan Ma and Fenglu Hong and Vamsidhar Kamanuru and Jay Rainton and Chen Wu and Mengmeng Ji and Hanchen Li and Urmish Thakker and James Zou and Kunle Olukotun},
   keywords = {cs.AI,cs.CL,cs.LG},
   month = {10},
   title = {Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models},
   url = {https://www.arxiv.org/pdf/2510.04618},
   year = {2025}
}
@article{Zhang2025,
   abstract = {Multi-Hop Question Answering (MHQA), crucial for complex information retrieval, remains challenging for current Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems, which often suffer from hallucination, reliance on incomplete knowledge, and opaque reasoning processes. Existing RAG methods, while beneficial, still struggle with the intricacies of multi-step inference and ensuring verifiable accuracy. This research introduces TreeQA, a novel framework designed to significantly enhance the reliability and interpretability of LLM-RAG systems in MHQA tasks. TreeQA addresses these limitations by decomposing complex multi-hop questions into a hierarchical logic tree of simpler, verifiable sub-questions, integrating evidence from both structured knowledge bases (e.g., Wikidata) and unstructured text (e.g., Wikipedia), and employing an iterative, evidence-based validation and self-correction mechanism at each reasoning step to dynamically rectify errors and prevent their accumulation. Extensive experiments on four benchmark datasets (WebQSP, QALD-en, AdvHotpotQA, and 2WikiMultiHopQA) demonstrate TreeQA's superior performance, achieving Hit@1 scores of 87 %, 57 %, 53 %, and 59 %, respectively, representing improvements of 4 %-12 % over state-of-the-art LLM-RAG methods. These findings highlight the significant impact of structured, verifiable reasoning pathways in developing more robust, accurate, and interpretable knowledge-intensive AI systems, thereby enhancing the practical utility of LLMs in complex reasoning scenarios. Our code is publicly available at https://github.com/ACMISLab/TreeQA.},
   author = {Xiangrui Zhang and Fuyong Zhao and Yutian Liu and Panfeng Chen and Yanhao Wang and Xiaohua Wang and Dan Ma and Huarong Xu and Mei Chen and Hui Li},
   doi = {10.1016/J.KNOSYS.2025.114526},
   issn = {0950-7051},
   journal = {Knowledge-Based Systems},
   keywords = {Large language model,Logic tree,Multi-hop question answering,Retrieval-augmented generation},
   month = {11},
   pages = {114526},
   publisher = {Elsevier},
   title = {TreeQA: Enhanced LLM-RAG with logic tree reasoning for reliable and interpretable multi-hop question answering},
   volume = {330},
   url = {https://www.sciencedirect.com/science/article/pii/S0950705125015655?pes=vor&utm_source=scopus&getft_integrator=scopus},
   year = {2025}
}
@article{Zuo2025,
   abstract = {In natural language processing, tasks like trigger word extraction, event type recognition, and event relation extraction are essential. These tasks facilitate the extraction of salient information through detailed textual analysis, enhancing the semantic understanding of texts. The extraction of trigger words and event types often faces challenges due to polysemous words and complex sentence structures, which can impair semantic representation. To address this, this paper introduces a Dependency Syntactic Analysis model and proposes the Event Type Extraction Model based on Gravitational Network with Enhanced Dependency Semantics (GNEDS). This model clarifies complex relationships and structures among words with in sentences, significantly improving contextual information comprehension. This enables more accurate identification of trigger words and their contextual links, thereby enhancing the text’s semantic representation. Furthermore, traditional research in event relation recognition has primarily focused on intrasentential relations, but real-world texts often display multisentence event relations that involve complex contextual and implicit reasoning. To overcome the limitations of existing models in cross-sentence event relation extraction, this study introduces a Graph Convolutional Neural Network (GCN) and an innovative concept of document nodes. A new model, Document Event Relationship Extraction based on Graph Convolutional Network with Enhanced Dependency Semantics (GCNEDS) is proposed. It captures long distance dependencies between sentences within a document with greater accuracy, marking a significant advancement in the field of event type and relationship extraction based on dependent syntactic-semantic augmented graph networks. © 2025 The Authors.},
   author = {Min Zuo and Zexi Song and Qingchuan Zhang and Yueheng Liu and Di Wu and Yuanyuan Cai},
   doi = {10.1109/ACCESS.2025.3546963},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {BERT,Event type extraction,GCN,dependent syntax,event relation extraction,gravitational network},
   pages = {40169-40184},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Event Type and Relationship Extraction Based on Dependent Syntactic Semantic Augmented Graph Networks},
   volume = {13},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/86000800986?origin=resultslist#},
   year = {2025}
}
@article{Han2025,
   abstract = {Retrieval-augmented generation (RAG) is a powerful technique that enhances downstream task execution by retrieving additional information, such as knowledge, skills, and tools from external sources. Graph, by its intrinsic "nodes connected by edges" nature, encodes massive heterogeneous and relational information, making it a golden resource for RAG in tremendous real-world applications. As a result, we have recently witnessed increasing attention on equipping RAG with Graph, i.e., GraphRAG. However, unlike conventional RAG, where the retriever, generator, and external data sources can be uniformly designed in the neural-embedding space, the uniqueness of graph-structured data, such as diverse-formatted and domain-specific relational knowledge, poses unique and significant challenges when designing GraphRAG for different domains. Given the broad applicability, the associated design challenges, and the recent surge in GraphRAG, a systematic and up-to-date survey of its key concepts and techniques is urgently desired. Following this motivation, we present a comprehensive and up-to-date survey on GraphRAG. Our survey first proposes a holistic GraphRAG framework by defining its key components, including query processor, retriever, organizer, generator, and data source. Furthermore, recognizing that graphs in different domains exhibit distinct relational patterns and require dedicated designs, we review GraphRAG techniques uniquely tailored to each domain. Finally, we discuss research challenges and brainstorm directions to inspire cross-disciplinary opportunities. Our survey repository is publicly maintained at https://github.com/Graph-RAG/GraphRAG/.},
   author = {Haoyu Han and Yu Wang and Harry Shomer and Kai Guo and Jiayuan Ding and Yongjia Lei and Mahantesh Halappanavar and Ryan A. Rossi and Subhabrata Mukherjee and Xianfeng Tang and Qi He and Zhigang Hua and Bo Long and Tong Zhao and Neil Shah and Amin Javari and Yinglong Xia and Jiliang Tang},
   month = {1},
   title = {Retrieval-Augmented Generation with Graphs (GraphRAG)},
   url = {https://arxiv.org/pdf/2501.00309v2},
   year = {2025}
}
@article{Zheng2025,
   abstract = {The aim of Knowledge Graph Question Answering (KGQA) is to find the answer entity by utilizing the Knowledge Graph (KG). Despite remarkable successes in recent years, the existing multi-hop KGQA research still faces numerous challenges. First, a multi-hop question often contains multiple entities and their relationships, and the semantic information is complex. The current methods extract the semantics of the question through an encoder that cannot completely extract the complex and rich semantic information in the multi-hop questions. Second, current question answering models use the coarse information filtering mechanism in the process of reasoning, which lead to the loss of effective information and introduce additional noise. To address these issues, we propose a Thoughtful and Cautious Reasoning framework for Knowledge Graph Question Answering (TCR-KGQA). We design a new question encoder that can extract and fully fuse the local semantic information of the question at different levels, focusing on the unique local features of the multi-hop question text. Based on the advantages of Gated Recurrent Unit (GRU) for information filtering, we propose a loop instruction update framework based on residual-GRU to effectively capture key information in the reasoning process. Extensive experiments on three broad benchmark datasets demonstrate the effectiveness of our model on KGQA tasks, and it also yields excellent results in the case of incomplete knowledge graphs with missing question–answer pairs.},
   author = {Yinghao Zheng and Ling Lu and Yang Hu and Yinong Chen and Aijuan Wang},
   doi = {10.1016/J.ENGAPPAI.2025.110479},
   issn = {0952-1976},
   journal = {Engineering Applications of Artificial Intelligence},
   keywords = {Graph neural network,Knowledge graph,Local semantic information,Multi-hop question answering},
   month = {6},
   pages = {110479},
   publisher = {Pergamon},
   title = {Thoughtful and cautious reasoning: A fine-tuned knowledge graph-based multi-hop question answering framework},
   volume = {150},
   url = {https://www.sciencedirect.com/science/article/abs/pii/S0952197625004798?via%3Dihub},
   year = {2025}
}
@article{Cai2024,
   abstract = {In the rapidly evolving domain of question answering systems, the ability to integrate machine comprehension with relational reasoning stands paramount. This paper introduces a novel architecture, the Dependent Syntactic Semantic Augmented Graph Network (DSSAGN), designed to address the intricate challenges of multi-hop question answering. By ingeniously leveraging the synergy between syntactic structures and semantic relationships within knowledge graphs, DSSAGN offers a breakthrough in interpretability, scalability, and accuracy. Unlike previous models that either fall short in handling complex relational paths or lack transparency in reasoning, our framework excels by embedding a sophisticated mechanism that meticulously models multi-hop relations and dynamically prioritizes the syntactic–semantic context.},
   author = {Songtao Cai and Qicheng Ma and Yupeng Hou and Guangping Zeng},
   doi = {10.3390/ELECTRONICS13081436},
   issn = {2079-9292},
   issue = {8},
   journal = {Electronics 2024, Vol. 13, Page 1436},
   keywords = {based multi,deep learning,hop QA,knowledge graph,knowledge graph embedding,question answering},
   month = {4},
   pages = {1436},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Knowledge Graph Multi-Hop Question Answering Based on Dependent Syntactic Semantic Augmented Graph Networks},
   volume = {13},
   url = {https://www.mdpi.com/2079-9292/13/8/1436/htm https://www.mdpi.com/2079-9292/13/8/1436},
   year = {2024}
}
@article{Edge2025,
   abstract = {The use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs) to answer questions over private and/or previously unseen document collections. However, RAG fails on global questions directed at an entire text corpus, such as "What are the main themes in the dataset?", since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of text indexed by typical RAG systems. To combine the strengths of these contrasting methods, we propose GraphRAG, a graph-based approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text. Our approach uses an LLM to build a graph index in two stages: first, to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that GraphRAG leads to substantial improvements over a conventional RAG baseline for both the comprehensiveness and diversity of generated answers.},
   author = {Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Dasha Metropolitansky and Robert Osazuwa Ness and Jonathan Larson},
   title = {From Local to Global: A GraphRAG Approach to Query-Focused Summarization},
   url = {https://github.com/microsoft/graphrag.},
   year={2025}
}
@article{Ning2025,
   abstract = {With the advancement of web techniques, they have significantly revolutionized various aspects of people’s lives. Despite the importance of the web, many tasks performed on it are repetitive and time-consuming, negatively impacting the overall quality of life. To efficiently handle these tedious daily tasks, one of the most promising approaches is to advance autonomous agents to incorporate human-like intelligence based on Artificial Intelligence (AI) techniques, referred to as AI Agents. AI Agents offer significant advantages in handling such tasks since they can operate continuously without fatigue or performance degradation. Therefore, leveraging AI Agents – termed WebAgents in the context of web – to automatically assist people in handling tedious daily tasks can dramatically enhance productivity and efficiency. Recently, Large Foundation Models (LFMs) containing billions of parameters have exhibited human-like language understanding and reasoning capabilities, showing proficiency in performing various complex tasks. This naturally raises the question: ‘Can LFMs be utilized to develop powerful AI Agents that automatically handle web tasks, providing significant convenience to users?’ To fully explore the potential of LFMs, extensive research has emerged on WebAgents designed to complete daily web tasks according to user instructions, significantly enhancing the convenience of daily human life. In this survey1, we comprehensively review existing research studies on WebAgents across three key aspects: architectures, training, and trustworthiness. Additionally, several promising directions for future research are explored to provide deeper insights. © 2025 Copyright held by the owner/author(s)},
   author = {Liangbo Ning and Ziran Liang and Zhuohang Jiang and Haohao Qu and Yujuan Ding and Wenqi Fan and Xiao Yong Wei and Shanru Lin and Hui Liu and Philip S. Yu and Qing Li},
   doi = {10.1145/3711896.3736555},
   isbn = {9798400714542},
   issn = {2154817X},
   journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
   keywords = {AI Agents,AI Assistants,Fine-tuning,Large Foundation Models,Pre-training,Prompting,WebAgents},
   month = {8},
   pages = {6140-6150},
   publisher = {Association for Computing Machinery},
   title = {A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models},
   volume = {2},
   url = {https://scopus.proxyuao.elogim.com/pages/publications/105014313673?origin=resultslist},
   year = {2025}
}
@article{Li2025,
   abstract = {Advancements in large language models (LLMs) have transformed AI-driven education, enabling innovative applications across various learning and teaching domains. However, LLMs still face several challenges, including hallucination and static internal knowledge, which hinder their reliability in educational settings. Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving relevant information from an external knowledge base and incorporating it into the LLM's generation process. This approach improves factual accuracy and enables dynamic knowledge updates, making LLMs particularly suitable for educational applications. In this paper, we comprehensively review existing research that integrates RAG into educational scenarios. We first clarify the definition and workflow of RAG, and following the indexing mechanism of RAG, we introduce different types of retrievers and generation optimization methods. As the main focus of this work, we explore the practical applications of RAG in education, covering interactive learning systems, generation and assessment of educational content, and large-scale deployment in educational ecosystems. Based on our comprehensive review, this paper discusses existing challenges and future directions, including mitigating hallucinations, ensuring the completeness and timeliness of retrieved knowledge, reducing computational costs, and enhancing multimodal support for RAG-based educational applications.},
   author = {Zongxi Li and Zijian Wang and Weiming Wang and Kevin Hung and Haoran Xie and Fu Lee Wang},
   doi = {10.1016/J.CAEAI.2025.100417},
   issn = {2666-920X},
   journal = {Computers and Education: Artificial Intelligence},
   keywords = {Artificial intelligence in education,Educational applications,Large language models (LLMs),Retrieval-augmented generation (RAG)},
   month = {6},
   pages = {100417},
   publisher = {Elsevier},
   title = {Retrieval-augmented generation for educational application: A systematic survey},
   volume = {8},
   url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000578?pes=vor&utm_source=scopus&getft_integrator=scopus},
   year = {2025}
}
@article{Gupta2024,
   abstract = {This paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its evolution from foundational concepts to the current state of the art. RAG combines retrieval mechanisms with generative language models to enhance the accuracy of outputs, addressing key limitations of LLMs. The study explores the basic architecture of RAG, focusing on how retrieval and generation are integrated to handle knowledge-intensive tasks. A detailed review of the significant technological advancements in RAG is provided, including key innovations in retrieval-augmented language models and applications across various domains such as question-answering, summarization, and knowledge-based tasks. Recent research breakthroughs are discussed, highlighting novel methods for improving retrieval efficiency. Furthermore, the paper examines ongoing challenges such as scalability, bias, and ethical concerns in deployment. Future research directions are proposed, focusing on improving the robustness of RAG models, expanding the scope of application of RAG models, and addressing societal implications. This survey aims to serve as a foundational resource for researchers and practitioners in understanding the potential of RAG and its trajectory in natural language processing.},
   author = {Shailja Gupta and Rajesh Ranjan and Surya Narayan Singh},
   keywords = {Artificial Intelligence (AI),Information Retrieval,Large Language Model (LLM) Introduction,Machine Learning (ML),Natural Language Processing (NLP),Retrieval-Augmented Generation (RAG)},
   month = {10},
   title = {A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions},
   url = {https://arxiv.org/pdf/2410.12837},
   year = {2024}
}
@article{Sapkota2025,
   abstract = {Information fusion, in the context of the Generative AI era, must distinguish AI Agents from Agentic AI. This review critically distinguishes between AI Agents and Agentic AI, offering a structured, conceptual taxonomy, application mapping, and analysis of opportunities and challenges to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven and enabled by LLMs and LIMs for task-specific automation. Generative AI is positioned as a precursor providing the foundation, with AI agents advancing through tool integration, prompt engineering, and reasoning enhancements. We then characterize Agentic AI systems, which, in contrast to AI Agents, represent a paradigm shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and coordinated autonomy. Through a chronological evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both AI agents and agentic AI paradigms. Application domains enabled by AI Agents such as customer support, scheduling, and data summarization are then contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure, and propose targeted solutions such as ReAct loops, retrieval-augmented generation (RAG), automation coordination layers, and causal modeling. This work aims to provide a roadmap for developing robust, scalable, and explainable AI-driven systems.},
   author = {Ranjan Sapkota and Konstantinos I Roumeliotis and Manoj Karkee},
   doi = {10.1016/j.inffus.2025.103599},
   keywords = {AI agents,Agentic AI,Conceptual taxonomy,Context awareness,Multi-agent systems},
   title = {AI Agents vs. Agentic AI: A Conceptual taxonomy, applications and challenges},
   url = {https://doi.org/10.1016/j.inffus.2025.103599},
   year = {2025}
}
@article{judge,
   abstract = {As large language models (LLMs) grow in capability and autonomy, evaluating their outputs especially in open-ended and complex tasks-has become a critical bottleneck. A new paradigm is emerging: using AI agents as the evaluators themselves. This "agent-as-a-judge" approach leverages the reasoning and perspective-taking abilities of LLMs to assess the quality and safety of other models, promising scalable and nuanced alternatives to human evaluation. In this review, we define the agent-as-a-judge concept, trace its evolution from single-model judges to dynamic multi-agent debate frameworks, and critically examine their strengths and shortcomings. We compare these approaches across reliability, cost, and human alignment, and survey real-world deployments in domains such as medicine, law, finance, and education. Finally, we highlight pressing challenges including bias, robustness, and meta-evaluation-and outline future research directions. By bringing together these strands, our review demonstrates how agent-based judging can complement (but not replace) human oversight , marking a step toward trustworthy, scal-able evaluation for next-generation LLMs.},
   author = {Fangyi Yu},
   keywords = {cs.AI},
   title = {When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs}
}
@article{Asaf2025,
   abstract = {The emergence of LLM-based agents represents a paradigm shift in AI, enabling autonomous systems to plan, reason, use tools, and maintain memory while interacting with dynamic environments. This paper provides the first comprehensive survey of evaluation methodologies for these increasingly capable agents. We systematically analyze evaluation benchmarks and frameworks across four critical dimensions: (1) fundamental agent capabilities, including planning, tool use, self-reflection, and memory; (2) application-specific benchmarks for web, software engineering , scientific, and conversational agents; (3) benchmarks for generalist agents; and (4) frameworks for evaluating agents. Our analysis reveals emerging trends, including a shift toward more realistic, challenging evaluations with continuously updated benchmarks. We also identify critical gaps that future research must address-particularly in assessing cost-efficiency, safety, and robustness, and in developing fine-grained, and scalable evaluation methods. This survey maps the rapidly evolving landscape of agent evaluation, reveals the emerging trends in the field, identifies current limitations, and proposes directions for future research.},
   author = {Asaf Yehudai and Lilach Eden and Alan Li and Guy Uziel and Yilun Zhao and Roy Bar-Haim and Arman Cohan and Michal Shmueli-Scheuer},
   isbn = {2503.16416v1},
   title = {Survey on Evaluation of LLM-based Agents},
   year = {2025}
}
@article{Colombo2024,
   abstract = {Knowledge Graphs (KGs) have been used to organize large datasets into structured, interconnected information, enhancing data analytics across various fields. In the legislative context, one potential natural application of KGs is modeling the intricate set of interconnections that link laws and their articles with each other and the broader legislative context. At the same time, the rise of large language models (LLMs) such as GPT has opened new opportunities in legal applications, such as text generation and document drafting. Despite their potential, the use of LLMs in legislative contexts is critical since it requires the absence of hallucinations and reliance on up-to-date information, as new laws are published on a daily basis. This work investigates how Legislative Knowledge Graphs and LLMs can synergize and support legislative processes. We address three key questions: the benefits of using KGs for legislative systems, how LLM can support legislative activities by ensuring an accurate output, and how we can allow non-technical users to use such technologies in their activities. To this aim, we develop Legis AI Platform, an interactive platform focused on Italian legislation that enhances the possibility of conducting legislative analysis and that aims to support lawmaking activities.},
   author = {Andrea Colombo},
   doi = {10.1145/3627673.3680268},
   journal = {International Conference on Information and Knowledge Management, Proceedings},
   keywords = {graphrag,knowledge graph,large language models,laws,legislative systems},
   month = {9},
   pages = {5443-5446},
   publisher = {Association for Computing Machinery},
   title = {Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems},
   volume = {1},
   url = {http://arxiv.org/abs/2409.13252 http://dx.doi.org/10.1145/3627673.3680268},
   year = {2024}
}

@article{Sardina2024,
   abstract = {Knowledge Graphs (KGs) and their machine learning counterpart, Knowledge Graph Embedding Models (KGEMs), have seen ever-increasing use in a wide variety of academic and applied settings. In particular, KGEMs are typically applied to KGs to solve the link prediction task; i.e. to predict new facts in the domain of a KG based on existing, observed facts. While this approach has been shown substantial power in many end-use cases, it remains incompletely characterised in terms of how KGEMs react differently to KG structure. This is of particular concern in light of recent studies showing that KG structure can be a significant source of bias as well as partially determinant of overall KGEM performance. This paper seeks to address this gap in the state-of-the-art. This paper provides, to the authors' knowledge, the first comprehensive survey exploring established relationships of Knowledge Graph Embedding Models and Graph structure in the literature. It is the hope of the authors that this work will inspire further studies in this area, and contribute to a more holistic understanding of KGs, KGEMs, and the link prediction task.},
   author = {Jeffrey Sardina and John D. Kelleher and Declan O'Sullivan},
   doi = {10.1109/ICSC64641.2025.00008},
   isbn = {9798331524265},
   issn = {24729671},
   journal = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
   keywords = {Graph Structure,Knowledge Graph Embeddings,Knowledge Graphs,Link Prediction,Relational Learning,Review,Structure,Survey,Topology},
   month = {12},
   pages = {11-19},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A Survey on Knowledge Graph Structure and Knowledge Graph Embeddings},
   url = {https://arxiv.org/pdf/2412.10092},
   year = {2024}
}
@article{Kovriguina2025,
   abstract = {Multi-agent collaboration has a long established record in reinforcement learning, and has gained momentum in the recent years with the breakthroughs in language-based intelligence. At the same time, there has been demonstrated a significant potential of joining LLM...},
   author = {Liubov Kovriguina and Dmitry Mouromtsev and Peter Haase},
   doi = {10.1007/978-3-031-94931-9_8},
   isbn = {978-3-031-94931-9},
   issn = {1865-1356},
   journal = {Lecture Notes in Business Information Processing},
   keywords = {experience transfer between neuro-symbolic agents,knowledge graphs for shared memory representation,multi-agent reinforcement learning,ontology for multi-agent experience transfer,semantic memory for multi-agent teams},
   pages = {93-104},
   publisher = {Springer, Cham},
   title = {The MATRIX Ontology - Semantic Memory for Multi-agent Experience Transfer, Reasoning and and Interaction eXchange},
   volume = {556 LNBIP},
   url = {https://link.springer.com/chapter/10.1007/978-3-031-94931-9_8},
   year = {2025}
}
@article{Vaswani2017,
   abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
   author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
   month = {6},
   pages = {1},
   title = {Attention Is All You Need},
   url = {https://arxiv.org/pdf/1706.03762},
   year = {2017}
}
@article{Long2022,
   abstract = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
   author = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L Wainwright and Pamela Mishkin and Chong Zhang Sandhini Agarwal Katarina Slama Alex Ray John Schulman Jacob Hilton Fraser Kelton Luke Miller Maddie Simens Amanda Askell and Peter Welinder Paul Christiano and Jan Leike and Ryan Lowe},
   isbn = {2203.02155v1},
   title = {Training language models to follow instructions with human feedback},
   year={2022}
}
@article{Lewis2021,
   abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG)-models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
   author = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-Tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
   isbn = {2005.11401v4},
   title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
   url = {https://github.com/huggingface/transformers/blob/master/},
   year={2021}
}
@article{Xi2023,
   abstract = {For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many researchers have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. In this paper, we perform a comprehensive survey on LLM-based agents. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for agents. Building upon this, we present a general framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored for different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge from an agent society, and the insights they offer for human society. Finally, we discuss several key topics and open problems within the field. A repository for the related papers at https://github.com/WooooDyy/LLM-Agent-Paper-List.},
   author = {Zhiheng Xi and Wenxiang Chen and Xin Guo and Wei He and Yiwen Ding and Boyang Hong and Ming Zhang and Junzhe Wang and Senjie Jin and Enyu Zhou and Rui Zheng and Xiaoran Fan and Xiao Wang and Limao Xiong and Yuhao Zhou and Weiran Wang and Changhao Jiang and Yicheng Zou and Xiangyang Liu and Zhangyue Yin and Shihan Dou and Rongxiang Weng and Wensen Cheng and Qi Zhang and Wenjuan Qin and Yongyan Zheng and Xipeng Qiu and Xuanjing Huang and Tao Gui},
   title = {The Rise and Potential of Large Language Model Based Agents: A Survey},
   url = {https://github.com/WooooDyy/LLM-Agent-Paper-List.},
   year = {2023}
}
@article{Rasmussen2025,
   abstract = {We introduce Zep, a novel memory layer service for AI agents that outperforms the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR) benchmark. Additionally, Zep excels in more comprehensive and challenging evaluations than DMR that better reflect real-world enterprise use cases. While existing retrieval-augmented generation (RAG) frameworks for large language model (LLM)-based agents are limited to static document retrieval, enterprise applications demand dynamic knowledge integration from diverse sources including ongoing conversations and business data. Zep addresses this fundamental limitation through its core component Graphiti -- a temporally-aware knowledge graph engine that dynamically synthesizes both unstructured conversational data and structured business data while maintaining historical relationships. In the DMR benchmark, which the MemGPT team established as their primary evaluation metric, Zep demonstrates superior performance (94.8% vs 93.4%). Beyond DMR, Zep's capabilities are further validated through the more challenging LongMemEval benchmark, which better reflects enterprise use cases through complex temporal reasoning tasks. In this evaluation, Zep achieves substantial results with accuracy improvements of up to 18.5% while simultaneously reducing response latency by 90% compared to baseline implementations. These results are particularly pronounced in enterprise-critical tasks such as cross-session information synthesis and long-term context maintenance, demonstrating Zep's effectiveness for deployment in real-world applications.},
   author = {Preston Rasmussen and Zep Ai and Pavlo Paliychuk and Travis Beauvais and Jack Ryan and Daniel Chalef},
   month = {1},
   title = {Zep: A Temporal Knowledge Graph Architecture for Agent Memory},
   url = {https://arxiv.org/pdf/2501.13956},
   year = {2025}
}

@article{Marquez2025,
   abstract = {Large Language Models (LLMs) such as GPT-4o can handle a wide range of complex tasks with the right prompt. As per token costs are reduced, the advantages of fine-tuning Small Language Models (SLMs) for real-world applications -- faster inference, lower costs -- may no longer be clear. In this work, we present evidence that, for domain-specific tasks that require structured outputs, SLMs still have a quality advantage. We compare fine-tuning an SLM against prompting LLMs on the task of generating low-code workflows in JSON form. We observe that while a good prompt can yield reasonable results, fine-tuning improves quality by 10% on average. We also perform systematic error analysis to reveal model limitations.},
   author = {Orlando Marquez and Ayala Servicenow and Patrice Bechard Servicenow and Emily Chen Servicenow and Maggie Baird Servicenow and Jingfei Chen Servicenow},
   journal = {Proceedings of Workshop on Structured Knowledge for Large Language Models (SKnowLLM) at KDD 2025 (KDD Workshop '25)},
   keywords = {cs.AI,cs.CL,cs.LG},
   month = {7},
   title = {Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows},
   volume = {1},
   url = {https://arxiv.org/pdf/2505.24189v2},
   year = {2025}
}
@article{Maciej2025,
   abstract = {Large Language Models (LLMs) are revolutionizing the development of AI assistants capable of performing diverse tasks across domains. However, current state-of-the-art LLM-driven agents face significant challenges, including high operational costs and limited success rates on complex benchmarks like GAIA. To address these issues, we propose Knowledge Graph of Thoughts (KGoT), an innovative AI assistant architecture that integrates LLM reasoning with dynamically constructed knowledge graphs (KGs). KGoT extracts and structures task-relevant knowledge into a dynamic KG representation, iteratively enhanced through external tools such as math solvers, web crawlers, and Python scripts. Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively while also minimizing bias and noise. For example, KGoT achieves a 29% improvement in task success rates on the GAIA benchmark compared to Hugging Face Agents with GPT-4o mini. Moreover, harnessing a smaller model dramatically reduces operational costs by over 36× compared to GPT-4o. Improvements for other models (e.g., Qwen2.5-32B and Deepseek-R1-70B) and benchmarks (e.g., SimpleQA) are similar. KGoT offers a scalable, affordable, versatile, and high-performing solution for AI assistants.},
   author = {Maciej Besta and Eth Zurich and Lorenzo Paleari and Jia Hao and Andrea Jiang and Robert Gerstenberger and You Wu and Jón Gunnar and Hannesson Eth and Zurich Patrick and Iff Eth and Zurich Ales and Kubicek Eth and Zurich Piotr and Nyczyk Cledar and Diana Khimey and Nils Blach and Haiqiang Zhang and Tao Zhang and Zurich Peiran and Ma Eth and Zurich Grzegorz and Kwa´sniewski Kwa´sniewski and Hubert Niewiadomski and Torsten Hoefler},
   isbn = {2504.02670v6},
   keywords = {cs.AI,cs.CL,cs.IR,cs.LG},
   title = {AFFORDABLE AI ASSISTANTS WITH KNOWLEDGE GRAPH OF THOUGHTS},
   url = {https://github.com/spcl/knowledge-graph-of-thoughts}
}
@article{Xu2025,
   abstract = {Large Language Models (LLMs) are widely used as judges to evaluate response quality, providing a scalable alternative to human evaluation. However, most LLM judges operate solely on intrinsic text-based reasoning, limiting their ability to verify complex constraints or perform accurate computation. Motivated by the success of tool-integrated reasoning (TIR) in numerous tasks, we propose TIR-Judge, an end-to-end RL framework for training LLM judges that integrates a code executor for precise evaluation. TIR-Judge is built on three principles: (i) diverse training across verifiable and non-verifiable domains, (ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii) iterative RL that bootstraps directly from the initial model without distillation. On seven public benchmarks, TIR-Judge surpasses strong reasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and achieves listwise performance comparable to Claude-Opus-4 despite having only 8B parameters. Remarkably, TIR-Judge-Zero-trained entirely without distilled judge trajectories, matches the performance of distilled variants, demonstrating that tool-augmented judges can self-evolve through iterative reinforcement learning.},
   author = {Ran Xu and Jingjing Chen and Jiayu Ye and Yu Wu and Jun Yan and Carl Yang and Hongkun Yu},
   keywords = {cs.AI,cs.CL,cs.LG},
   pages = {2025-2035},
   title = {Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning},
   year = {2025}
}
@article{Tran2025,
   abstract = {With recent advances in Large Language Models (LLMs), Agentic AI has become phenomenal in real-world applications, moving toward multiple LLM-based agents to perceive, learn, reason, and act collaboratively. These LLM-based Multi-Agent Systems (MASs) enable groups of intelligent agents to coordinate and solve complex tasks collectively at scale, transitioning from isolated models to collaboration-centric approaches. This work provides an extensive survey of the collaborative aspect of MASs and introduces an extensible framework to guide future research. Our framework characterizes collaboration mechanisms based on key dimensions: actors (agents involved), types (e.g., cooperation, competition, or coopetition), structures (e.g., peer-to-peer, centralized, or distributed), strategies (e.g., role-based or model-based), and coordination protocols. Through a review of existing methodologies, our findings serve as a foundation for demystifying and advancing LLM-based MASs toward more intelligent and collaborative solutions for complex, real-world use cases. In addition, various applications of MASs across diverse domains, including 5G/6G networks, Industry 5.0, question answering, and social and cultural settings, are also investigated, demonstrating their wider adoption and broader impacts. Finally, we identify key lessons learned, open challenges, and potential research directions of MASs towards artificial collective intelligence.},
   author = {Khanh-tung Tran and Dung Dao and Hoang D Nguyen and Khanh-Tung Tran and Minh-Duong Nguyen and Quoc-Viet Pham},
   doi = {XXXXXXX.XXXXXXX},
   keywords = {Artificial Intelligence,Large Language Model,Multi-Agent Collaboration},
   title = {Multi-Agent Collaboration Mechanisms: A Survey of LLMs},
   volume = {1},
   url = {https://blogs.nvidia.com/blog/what-is-agentic-ai/},
   year = {2025}
}
@article{Weixin2023,
   abstract = {Expert feedback lays the foundation of rigorous research. However, the rapid growth of scholarly production and intricate knowledge specialization challenge the conventional scientific feedback mechanisms. High-quality peer reviews are increasingly difficult to obtain. Researchers who are more junior or from under-resourced settings have especially hard times getting timely feedback. With the breakthrough of large language models (LLM) such as GPT-4, there is growing interest in using LLMs to generate scientific feedback on research manuscripts. However, the utility of LLM-generated feedback has not been systematically studied. To address this gap, we created an automated pipeline using GPT-4 to provide comments on the full PDFs of scientific papers. We evaluated the quality of GPT-4's feedback through two large-scale studies. We first quantitatively compared GPT-4's generated feedback with human peer reviewer feedback in 15 Nature family journals (3,096 papers in total) and the ICLR machine learning conference (1,709 papers). The overlap in the points raised by GPT-4 and by human reviewers (average overlap 30.85% for Nature journals, 39.23% for ICLR) is comparable to the overlap between two human reviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The overlap between GPT-4 and human reviewers is larger for the weaker papers (i.e., rejected ICLR papers; average overlap 43.80%). We then conducted a prospective user study with 308 researchers from 110 US institutions in the field of AI and computational biology to understand how researchers perceive feedback generated by our GPT-4 system on their own papers. Overall, more than half (57.4%) of the users found GPT-4 generated feedback helpful/very helpful and 82.4% found it more beneficial than feedback from at least some human reviewers. While our findings show that LLM-generated feedback can help researchers, we also identify several limitations. For example, GPT-4 tends to focus on certain aspects of scientific feedback (e.g., 'add experiments on more datasets'), and often struggles to provide in-depth critique of method design. Together our results suggest that LLM and human feedback can complement each other.},
   author = {Weixin Liang and Yuhui Zhang and Hancheng Cao and Binglu Wang and Daisy Yi Ding and Xinyu Yang and Kailas Vodrahalli and Siyu He and Daniel Scott Smith and Yian Yin and Daniel A Mcfarland and James Zou},
   title = {Can large language models provide useful feedback on research papers? A large-scale empirical analysis},
    year= {2023}
}
@article{Jin2024,
   abstract = {Peer review is fundamental to the integrity and advancement of scientific publication. Traditional methods of peer review analyses often rely on exploration and statistics of existing peer review data, which do not adequately address the multivariate nature of the process, account for the latent variables, and are further constrained by privacy concerns due to the sensitive nature of the data. We introduce AgentReview, the first large language model (LLM) based peer review simulation framework, which effectively disentangles the impacts of multiple latent factors and addresses the privacy issue. Our study reveals significant insights, including a notable 37.1% variation in paper decisions due to reviewers' biases, supported by sociological theories such as the social influence theory, altruism fatigue, and authority bias. We believe that this study could offer valuable insights to improve the design of peer review mechanisms. Our code is available at https://github.com/Ahren09/AgentReview.},
   author = {Yiqiao Jin and Qinlin Zhao and Yiyang Wang and Hao Chen and Kaijie Zhu and Yijia Xiao and Jindong Wang},
   month = {10},
   title = {AgentReview: Exploring Peer Review Dynamics with LLM Agents},
   url = {https://arxiv.org/pdf/2406.12708v2},
   year = {2024}
}
@article{Meyerson2025,
   abstract = {LLMs have achieved remarkable breakthroughs in reasoning, insights, and tool use, but chaining these abilities into extended processes at the scale of those routinely executed by humans, organizations, and societies has remained out of reach. The models have a persistent error rate that prevents scale-up: for instance, recent experiments in the Towers of Hanoi benchmark domain showed that the process inevitably becomes derailed after at most a few hundred steps. Thus, although LLM research is often still benchmarked on tasks with relatively few dependent logical steps, there is increasing attention on the ability (or inability) of LLMs to perform long range tasks. This paper describes MAKER, the first system that successfully solves a task with over one million LLM steps with zero errors, and, in principle, scales far beyond this level. The approach relies on an extreme decomposition of a task into subtasks, each of which can be tackled by focused microagents. The high level of modularity resulting from the decomposition allows error correction to be applied at each step through an efficient multi-agent voting scheme. This combination of extreme decomposition and error correction makes scaling possible. Thus, the results suggest that instead of relying on continual improvement of current LLMs, massively decomposed agentic processes (MDAPs) may provide a way to efficiently solve problems at the level of organizations and societies.},
   author = {Elliot Meyerson and Giuseppe Paolo and Roberto Dailey and Hormoz Shahrzad and Olivier Francon and Conor F. Hayes and Xin Qiu and Babak Hodjat and Risto Miikkulainen},
   keywords = {cs.AI,cs.CL,cs.MA},
   month = {11},
   title = {Solving a Million-Step LLM Task with Zero Errors},
   url = {https://arxiv.org/pdf/2511.09030},
   year = {2025}
}
@misc{Miles2019,
   author = {D. Anthony Miles},
   month = {1},
   title = {ARTICLE: Achieving Alignment: How to Develop Research Alignment In A Dissertation Study},
   url = {https://www.academia.edu/39588501/ARTICLE_Achieving_Alignment_How_to_Develop_Research_Alignment_In_A_Dissertation_Study},
   year = {2019}
}
@article{Covvey2023,
   abstract = {Good science is driven by rigorous questions. Much like the foundation of a house, a research question must be carefully constructed to prevent downstream problems in project execution. And yet, pharmacy researchers and scholars across all career stages may find themselves struggling when developing research questions. The purpose of this commentary is to provide useful guidance on composing and evaluating rigorous research questions. A variety of frameworks, such as PICO (Patient/population; Intervention; Comparison; Outcome), are available to researchers and can assist them in ensuring that their research question has covered all relevant components. Additionally, the FINER (Feasible; Interesting; Novel; Ethical; and Relevant) criteria can help researchers with evaluating their research questions for practical considerations. Finally, building awareness of common pitfalls when composing research questions can aid researchers to avoid issues that they may not otherwise discover until their manuscript undergoes peer review.},
   author = {Jordan R. Covvey and Chyna McClendon and Michael R. Gionfriddo},
   doi = {10.1016/J.SAPHARM.2023.09.009},
   issn = {15517411},
   issue = {1},
   journal = {Research in social \& administrative pharmacy : RSAP},
   keywords = {Biomedical research,Peer review,Pharmacy research,Research,Research design},
   month = {1},
   pages = {66},
   pmid = {37838572},
   publisher = {Elsevier Inc.},
   title = {Back to the basics: guidance for formulating good research questions},
   volume = {20},
   url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC11129835/},
   year = {2023}
}
@article{Huang2025,
   abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), fueling a paradigm shift in information acquisition. Nevertheless, LLMs are...},
   author = {Lei Huang and Weijiang Yu and Weitao Ma and Weihong Zhong and Zhangyin Feng and Haotian Wang and Qianglong Chen and Weihua Peng and Xiaocheng Feng and Bing Qin and Ting Liu},
   doi = {10.1145/3703155},
   issn = {15582868},
   issue = {2},
   journal = {ACM Transactions on Information Systems},
   keywords = {Factuality,Faithfulness,Hallucination,Large Language Models},
   month = {1},
   publisher = {ACMPUB27New York, NY},
   title = {A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
   volume = {43},
   url = {/doi/pdf/10.1145/3703155?download=true},
   year = {2025}
}
@article{Zhuang2025,
   abstract = {Large language models (LLMs) have significantly impacted human society, influencing various domains. Among them, academia is not simply a domain affected by LLMs, but it is also the pivotal force in the development of LLMs. In academic publication, this phenomenon is represented during the incorporation of LLMs into the peer review mechanism for reviewing manuscripts. LLMs hold transformative potential for the full-scale implementation of automated scholarly paper review (ASPR), but they also pose new issues and challenges that need to be addressed. In this survey paper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin with a survey to find out which LLMs are used to conduct ASPR. Then, we review what ASPR-related technological bottlenecks have been solved with the incorporation of LLM technology. After that, we move on to explore new methods, new datasets, new source code, and new online systems that come with LLMs for ASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and investigate the attitudes and reactions of publishers and academia to ASPR. Lastly, we discuss the challenges and future directions associated with the development of LLMs for ASPR. This survey serves as an inspirational reference for the researchers and can promote the progress of ASPR for its actual implementation.},
   author = {Zhenzhen Zhuang and Jiandong Chen and Hongfeng Xu and Yuwen Jiang and Jialiang Lin},
   doi = {10.1016/j.inffus.2025.103332},
   isbn = {2501.10326v2},
   keywords = {cs.AI,cs.CL,cs.DL},
   month = {6},
   title = {Large language models for automated scholarly paper review: A survey},
   url = {https://arxiv.org/pdf/2501.10326v2 http://dx.doi.org/10.1016/j.inffus.2025.103332},
   year = {2025}
}
@article{Ibrahim2024,
   abstract = {Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) enhances the interpretability and performance of AI systems. This research comprehensively analyzes this integration, classifying approaches into three fundamental paradigms: KG-augmented LLMs, LLM-augmented KGs, and synergized frameworks. The evaluation examines each paradigm’s methodology, strengths, drawbacks, and practical applications in real-life scenarios. The findings highlight the substantial impact of these integrations in fundamentally improving real-time data analysis, efficient decision-making, and promoting innovation across various domains. In this paper, we also describe essential evaluation metrics and benchmarks for assessing the performance of these integrations, addressing challenges like scalability and computational overhead, and providing potential solutions. This comprehensive analysis underscores the profound impact of these integrations on improving real-time data analysis, enhancing decision-making efficiency, and fostering innovation across various domains.},
   author = {Nourhan Ibrahim and Samar Aboulela and Ahmed Ibrahim and Rasha Kashef},
   doi = {10.1007/S44163-024-00175-8},
   isbn = {0123456789},
   issn = {2731-0809},
   issue = {1},
   journal = {Discover Artificial Intelligence 2024 4:1},
   keywords = {Artificial Intelligence,Computer Science,Engineering,Ms) ·,Retrieval augmentation generation (RAG),Retrieval augmentation generation (RAG) ·,general},
   month = {11},
   pages = {76-},
   publisher = {Springer},
   title = {A survey on augmenting knowledge graphs (KGs) with large language models (LLMs): models, evaluation metrics, benchmarks, and challenges},
   volume = {4},
   url = {https://link.springer.com/article/10.1007/s44163-024-00175-8},
   year = {2024}
}
